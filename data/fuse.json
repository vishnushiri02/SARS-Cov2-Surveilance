{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Master Thesis documentation","n":0.577},"1":{"v":"# [[Growth_rate_Estimation]]\n","n":0.707}}},{"i":2,"$":{"0":{"v":"Templates","n":1}}},{"i":3,"$":{"0":{"v":"Meeting Notes Template","n":0.577},"1":{"v":"## Attendees\n\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- [Dr. Daniela Börnigen](https://rki.webex.com/meet/boernigend)\n\n## Work done so far\n\n<!-- What has been done so far -->\n\n## Doubts\n\n<!-- Any doubts to be cleared -->\n\n\n\n## Next Step\n\n<!-- What should  I work on till the next meeting-->\n\n## Tasks\n\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- [ ]\n- [ ]\n- [ ]\n- [ ]\n","n":0.102}}},{"i":4,"$":{"0":{"v":"Checklist","n":1},"1":{"v":"\n  - [ ] \n  - [ ] \n  - [ ] \n","n":0.277}}},{"i":5,"$":{"0":{"v":"Meet","n":1}}},{"i":6,"$":{"0":{"v":"2023","n":1}}},{"i":7,"$":{"0":{"v":"09","n":1}}},{"i":8,"$":{"0":{"v":"Implementation of the R packages","n":0.447},"1":{"v":"_Edit the [[templates.meet]] note to change this template generated for Dendron Meeting Notes._\n\n## Attendees\n\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- Dr. Daniela Börnigen\n\n## Work done so far\n[[Tasks|meet.2023.08.17#tasks]]\n<!-- What has been done so far -->\n\n## Doubts\n\n<!-- Any doubts to be cleared -->\n\n1. [[Doubts EpiEstim|growth_rate_estimation.Methods to estimate R.R_packages#doubts-epiestim]]\n2. [[Doubts|growth_rate_estimation.Methods to estimate R#doubts]]\n\n\n\n## Next Step\n\n<!-- What should  I work on till the next meeting-->\n\n## Tasks\n\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n![Notes of Dr.Daniela](assets/images/Next_tasks_12-9-23.png)\n- [X] Find the difference in the implementation of WT method in EpiEstim and R_0 package\n- [ ] Download data from GSAID using the specified R package\n- [ ] Try the EpiEstim and R_0 package on the SARS Cov Data set\n- [ ] Code to plot the SARS Cov data, take inspiration from Gerstung lab\n- [ ] Try to get R packages to calculate more epidemic values like growth rate advantaage, variant proportions, etc\n","n":0.074}}},{"i":9,"$":{"0":{"v":"08","n":1}}},{"i":10,"$":{"0":{"v":"The extra resources","n":0.577},"1":{"v":"\n## Attendees\n\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- Dr. Daniela Börnigen\n\n## Work done so far\n\n<!-- What has been done so far -->\nRead the papers\n## Doubts\n\n<!-- Any doubts to be cleared -->\n## Next Step\nImplementing the model data provided by each R package - EpiEstim and R_0 package\n<!-- What should  I work on till the next meeting-->\n\n## Tasks\n\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- [x] Try running the R package on data being provided\n\n","n":0.094}}},{"i":11,"$":{"0":{"v":"Implementation of gerstung lab paper","n":0.447},"1":{"v":"\n\n## Attendees\n\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- Dr. Daniela Börningen\n- Vishnushiri\n\n## Work done so far\n\n<!-- What has been done so far -->\n\nComprehension of the model used in the gerstung lab paper. Statistical distributions that were used were also intuitively understood. Distributions like negative binomial, Dirichlet multinomial; Concepts like spline function, convolution, multinomial and multivariate were all read and understood.\n\n### Gerstung Lab paper\n\n[[Doubts and answers|Growth_Rate_Estimation.GerstungLab#doubts-and-answers]]\n\n\n<!-- Any doubts to be cleared -->\n\n## Next Step\n\n<!-- What should  I work on till the next meeting-->\n- We are not going to implement the Gerstung lab paper\n- See if gerstung lab program works for their data set, modulate the parameters and see what happens\n- Look into more approaches that handle epidemic data and choose what can be reimplemented.\n\n## Tasks\n\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- [-] Run the program with their data and then try repeating with german data\n\n> There are lots of dependency issues between numpyro,jaxlib and genomic surveillance. The package needs old version of numpyro and jaxlib which are giving tough time. pip is able to install jaxlib version 0.1.75 onwards with cuda but genomic surveillance needs package 0.1.62\n\n- [X] Read given papers and about the R package\n  ","n":0.065}}},{"i":12,"$":{"0":{"v":"05","n":1}}},{"i":13,"$":{"0":{"v":"Literature search","n":0.707},"1":{"v":"<!--Edit the [[templates.meet]] note to change this template generated for Dendron Meeting Notes.-->\n\n## Attendees\n\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\nDr. Daniela Börnigen\n\n## Work done so far\n\n  - [x] Literature study to collect already existing studies [[Growth_rate_Estimation]]\n  - [x] Glossary with Epidemiological Terms [[Growth_Rate_Estimation.Glossary]]\n  \n\n\n<!-- What has been done so far -->\n\n## Doubts\n\n<!-- Any doubts to be cleared -->\n\n## Next step\n\n<!-- What should  I work on till the next meeting-->\n- Try to incorporate SARS Covid2 data in the collected models to esitmate growth rate\n\n## Tasks\n\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n    - [ ] Read the paper\n    - [ ] Understand the model\n    - [ ] Get the SARS Cov-2 Data\n    - [ ] Incorporate the data in the model\n\n\n\n","n":0.079}}},{"i":14,"$":{"0":{"v":"WorkLog","n":1},"1":{"v":"|DATE|TASK THAT WAS HANDLED| DESCRIPTION OF THE WORK PERFORMED TODAY|\n|--|--|--|\n|22-6-23| [[Model study\\|meet.2023.05.31#next-step]]|Managed to read and understand the few fundamentals of the model and started the [[Growth_Rate_Estimation.GerstungLab]] note|\n|23-6-23|[[Model study\\|meet.2023.05.31#next-step]]|Continued Reading through the model. I am not keeping well today|\n|24-6-23 to 13-7-23| No Tasks done | Reason: Events in India|\n|14-7-23| Catching up| Reading through my notes|\n|17-7-23| [[Model study\\|meet.2023.05.31#next-step]] | Continuing to read through the paper and noted few doubts|\n|18-7-23| Work at Centogene||\n|19-7-23| Work at Centogene||\n|20-7-23 to 24-7-23| Break| Not in town|\n|25 -7- 23|[[Model study\\|meet.2023.05.31#next-step]]|Understanding the basic intuition of the model by brushing through concepts - basic statistics, convolution.|\n|26-7-23|[[Model study\\|meet.2023.05.31#next-step]]| The growth rate is obtained by differentiating the spline functions - So tried to understand spline interpolation and cubic spline basis|\n|27-7-23|[[Model study\\|meet.2023.05.31#next-step]]|Trying to get more sense regarding incidence|\n|28-7-23|[[Model study\\|meet.2023.05.31#next-step]]|Revisiting Binomial and Negative binomial distribution, Difference between incidence and growth rate. How can growth rate be calculated from incidence.|\n|29,30-7-23| - | Weekend|\n|31-7-23|[[Model study\\|meet.2023.05.31#next-step]]|Gamma Distribution, Growth rate and instantaneous reproduction number.|\n|1-8-23|[[Model study\\|meet.2023.05.31#next-step]]|Genomic Prevalance, Logit function|\n|2-8-23|Work at Centogene||\n|3-8-23|[[Model study\\|meet.2023.05.31#next-step]]|Logit and logistic function,Dirichlet–Multinomial Models, Genomic prevalance|\n|4-8-23|[[Model study\\|meet.2023.05.31#next-step]]|Beta Distribution,Dirichlet distribution|\n|5,6-8-23|-|Weekend|\n|7-8-23|[[Model study\\|meet.2023.05.31#next-step]]| Dirichlet distribution and Dirichlet-multinomial distribution|\n|8-8-23|[[Model study\\|meet.2023.05.31#next-step]]|Read through the paper, Tried to get the overall picture of the model intuitively and also tried to answer my doubts|\n|9-8-23|[[meet.2023.08.09]]|Meeting, Filled the document with the answers to the doubts, pushed to git|\n|10-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|started with the Cori paper,skimming through the paper|\n|11-8-23|Work at Centogene||\n|12,13-8-23|-|Weekend|\n|14-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Understanding Poisson Distribution - a bit tricky|\n|15-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Understanding Gamma distribution|\n|16-8-23||Not well|\n|17-8-23|Virtual meet<br> Cori paper<br> Doc appointment|Bayessian inference|\n|18-8-23|Work at Centogene||\n|19,20-8-23|Weekend||\n|21-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Finishing Cori & supp paper|\n|22-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Obadia paper,Moment Generating function, R square|\n|23-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Finishing Obadia paper|\n|24,25-8-23| Flying to India||\n|26,27-8-23|Weekend||\n|28-8-23|Work at centogene||\n|29-8-23|Work at centogene||\n|30-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Wallinga_Teunis Paper|\n|31-8-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Wallinga_Teunis Paper,Thomson paper|\n|1-9-23|[[More methods to get growth rate\\|meet.2023.08.09#next-step]]|Thomson paper|\n|2,3-9-23|Weekend||\n|4-9-23|[[Trying out The R Packages\\|meet.2023.08.17#tasks]]| Preparing for the meeting and planning for the next works, Setting-up R and Rstudio, Started with EpiEstim|\n|5-9-23|[[Trying out The R Packages\\|meet.2023.08.17#tasks]]| Finishing EpiEstim reimplementing the given demo|\n|6-9-23|Mixture of tasks|Half day working for centogene, Half day reading more about MCMC|\n|7-9-23|Mixture of tasks|3/4 day working for centogene, 1/4 day reading Thomson paper again to clarify few doubts|\n|8-9-23|Mixture of tasks| 5.5 hrs at hospital, 2 hrs Centogene, Revisiting EpiEstim reimplementation to be sure I understood everything|\n|9-9-23|[[Trying out The R Packages\\|meet.2023.08.17#tasks]]|Trying out the commands of the $R_0$ package|\n|10-9-23|Sunday|-|\n|11-9-23|[[Trying out The R Packages\\|meet.2023.08.17#tasks]]|1. Preparing for the meeting - git repository and pages updation 2. Hospital visit 3.5 hrs 3. Looked into the manuals of both the packages one more time (concentrting on the confidence interval).\n|12-9-23|[[Trying out The R Packages\\|meet.2023.08.17#tasks]]| Reading Wallinga Liptch paper, moment generating function, meeting.|\n|13-9-23|Not feeling well| -|\n|14-9-23|[[Tasks\\|meet.2023.09.11#tasks]]| Trying to equate wallinga teunis method in both the packages, Checking for other R packages to estimate epidemiology features.reading into packages like surveilence,epiR,mem etc|\n|15-9-23|Work at Centogene||\n|16-9-23|[[Tasks\\|meet.2023.09.11#tasks]]| spent 3 hours trying to understand surveillance package.|\n|17-9-23|Sunday||\n|18-9-23|Work at centogene| |\n|19-9-23|[[Tasks\\|meet.2023.09.11#tasks]]| Explored GISAID and GISAIDR, tried to download the meta data and mutation data, the default download functon in the GISAIDR package only downloads meta data but not data regarding mutation, so working on changing the download function.|\n|20,21,22-9-23|Hospital readmission|-|\n|23-9-23|[[Tasks\\|meet.2023.09.11#tasks]]| Downloading all the data from GISAID|\n\n\n","n":0.044}}},{"i":15,"$":{"0":{"v":"Growth_rate_Estimation","n":1},"1":{"v":"# Existing methods to model the growth rate\n\n|Sno|Model | Description | Name of the microorganism | Reference | Data Used | Notes|\n|---|------|-------|------------|------|-------|------|\n|1|1. Genomic Surveilance model <br> 2. Hierarchical Bayesian statistical model <br> 3.multivariate logistic regression model  | 1. Subset of 600,000 viral sample sequances were used to characterize the [[Epidemic Growth rate \\|Growth_Rate_Estimation.Glossary#epidemic-growth-rate]] and geographical spread of different SARS CoV-2 lineages <br> 2. The model also calculates total and lineage-specific local incidences and time-dependent growth rates and approximate reproduction numbers R<sub>t</sub> by negative binomial spline fitting of the number of daily positive PCR tests|SARS CoV-2|[Vöhringer, H.S., et al. Genomic reconstruction of the SARS-CoV-2 epidemic in England. Nature 600, 506–511 (2021). ](https://doi.org/10.1038/s41586-021-04069-y)| Positive case data along with the sequences | 1. The effect of immunity is currently not modelled - this can have impact on the spread of a particular lineage.<br> 2. Stochastic growth events are not fully accounted so the estimated growth rate will not reflect viral tranmissibility<br> 3. In its current form, the model accounts for only a single introduction event per LTLA <br> 4. The modelled curves are smoothed over intervals of approximately 7 d.|\n|2|1. Simple exponential Growth model <br> 2. Poisson likelihood framework is adopted for data fitting <br>  | R package _EpiEstim_ used to calculate the instatntaneous effective reproductive number of 12 African countries in order to show the potential of COVID-19 to spread across the region.|SARS CoV-2|[Musa, S.S., et al. Estimation of exponential growth rate and basic reproduction number of the coronavirus disease 2019 (COVID-19) in Africa. Infect Dis Poverty 9, 96 (2020).](https://doi.org/10.1186/s40249-020-00718-y)|1.Daily number of Covid-cases - time series data.<br>|1.Estimation for the early stages of the pandemic <br> 2. R<sub>0</sub> is also computed. <br> 3. SI that was used is from the estimates based on cases obtained in china|\n|3|stochastic SHARUCD-type model—an extension of the well known simple SIR model| 1. The model is used to estimate the [[Effective Reproduction Number\\|Growth_Rate_Estimation.Glossary#reffective-reproduction-number]] and momentary growth rates for hospital data.<br> 2. The collected total number of positive cases were categorised into hospital admissions, ICU admissions, recovered, deceased. These categorised data are used in the SEIR model - infected class partitioned into severe infections prone to hospitalization (H) and mild, sub-clinical or asymptomatic infections (A). For severe infections prone to hospitalization, we assume that individuals could either recover R, be admitted to the ICU facilities U or or eventually deceased into class D.| SARS CoV-2| [Aguiar, et al. \"Reproduction ratio and growth rates: Measures for an unfolding pandemic.\" PLoS One 15.7 (2020): e0236620.](https://doi.org/10.1371/journal.pone.0236620)| Number of positive cases | The data is collected from March 4 2020 to May 9 2020. The frequency at which the data is collected is not known. The model is parameterised using the initial pandemic data.|\n|4|Exponential growth model  |Estimation of the transmissibility of 2019-nCoV via the basic reproduction number, R<sub>0</sub>, based on the limited data in the early phase of the outbreak. R<sub>0</sub> is obtained using the estimated intrinsic growth rate.|SARS Cov-2|[Zhao, Shi, et al. \"Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak.\" International journal of infectious diseases 92 (2020): 214-217.](https://doi.org/10.1016/j.ijid.2020.01.050)| Positive test time series data|1. Non linear least square was used for data fitting and parameter estimation<br> 2.SI information from SARS and MERS, which share a similar pathogen as 2019-nCoV were used.|\n|5|1.Smoothing splines are a quick method to estimate maximum growth <br> 2. Classsical logistic growth model written as analytical solution of the differential equation |Growthrates package of R aims to streamline estimation of growth rates from direct or indirect measures of population density (e.g. cell counts, optical density or fluorescence) determined in batch experiments or field observations | different species of bacteria, archaea, protists, and metazoa | [Estimation of Growth Rates with Package growthrates, Part 1: Introduction Thomas Petzoldt](https://cran.r-project.org/web/packages/growthrates/vignettes/Introduction.html)| 1. Concentration <br> 2. time <br> 3. value of the indirect measure.| 1.Nonlinear fitting of parametric growth models like the logistic or the Gompertz growth model. Parametric model fitting is done by using package FME (Flexible Modelling Environment) of Soetaert and Petzoldt (2010). In addition to growth models given in closed form (i.e. empirical regression equations or analytical solutions of differential equations) it is also possible to use numerically integrated systems of differential equation. Such models are then solved with package `deSolve’ (Soetaert, Petzoldt, and Setzer 2010).<br> 2. Fitting of linear models to the period of exponential growth using the ``growth rates made easy method’’ of Hall et al. (2014) , <br>3. Nonparametric growthrate estimation by using smoothers. R contains several powerful smoothing methods, that can leveraged for this purpose. The currently implemented method uses function smooth.spline, similar to the package grofit (Kahm et al. 2010).| \n|6| 1. Target cell limited model <br> 2. mixed effects model| 1. The study aims to estimate reproduction number and growth/expansion rate at the early pathogenesis of HIV -1 infection. For this purpose samples from already HIV-1 infected persons are not considered for the study <br> 2. In the context of host viral dynamics, R0 is a measure of whether a virus can establish infection. It specifically measures how many cells a single infected cell will infect when there is no target cell limitation.  | HIV-1 | [Ribeiro, Ruy M et al. “Estimation of the initial viral growth rate and basic reproductive number during acute HIV-1 infection.” Journal of virology vol. 84,12 (2010): 6096-102.](https://doi.org/10.1128/JVI.00127-10)|HIV viral load data from the plasma of 51 donors. The data seems to be collected 10 times with an interval for each sample| 1. The time of infection for the sample collected is not known which is the t<sub>0</sub>. The work arbitarily defines the time of origin as as the time that the subject’s viral load first reached the limit of detection, 50 cp/ml, and call it t<sub>50</sub>. <br> 2. Linear mixed effects model is used for estimating the expansion rate|\n|7|1. Exponential growth model <br> 2. Polynomial growth model|The study aims to analyse the growth pattern of Ebola virus disease epidemic in different spatial scales  (regional, national, and subnational) in western Africa.<br> 3. The growth trend in the regional endemics followed a polynomial exponenetial function. | Ebola Virus|[Chowell, Gerardo et al. “The Western Africa ebola virus disease epidemic exhibits both global exponential and local polynomial growth rates.” PLoS currents vol. 7 ecurrents.outbreaks.8b55f4bad99ac5c5db3663e916803261. 21 Jan. 2015.](https://doi.org/10.1371%2Fcurrents.outbreaks.8b55f4bad99ac5c5db3663e916803261)|Weekly time series  of reported Ebola virus disease case numbers.| The local data was first plotted on the semi-logrithamic scale. Exponential growth is evident if a straight line fits well several consecutive disease generations of the epidemic curve, whereas a strong curvature in semi-logarithmic scale would be indicative of sub-exponential growth and a straight line fitted to the square-root transformed epidemic curve would be indicative of quadratic polynomial growth.|\n|8|[[Risk model\\|Growth_Rate_Estimation.Glossary#risk-model]]| 1. The study aims to develop a mathematical model to explain the cubic growth of AIDS and apply it in the homosexual population <br> 2. The risk-based model builds on the fact that the amount of 'risky' behaviour is not distributed equally among the population. It also assumes that the people with similar risk behaviour tend to primarly interact among themselves (biased mixing) rather than equally with others(homogenous mixing), finally the model incroporates the epidemologic data on the progression from initial HIV infection to AIDS. | HIV-AIDS|[Colgate, S A et al. “Risk behavior-based model of the cubic growth of acquired immunodeficiency syndrome in the United States.” Proceedings of the National Academy of Sciences of the United States of America vol. 86,12 (1989): 4793-7.](https://doi.org/10.1073/pnas.86.12.4793)||1. Homogenous mixing is assumed<br> 2. study assumes that the risk behaviour is distributed.<br> 3. Risk behaviour - New partner Rate and frequency of sexual contact.  |\n|9|  Emprical model | Development of improved maximal growth rate estimator and prediction of maximal growth rates from over 200,000 genomes, metagenome assembled genomes, and single-cell amplified genomes to survey growth potential across the range of prokaryotic diversity|Prokaryotic organisms|[Weissman, Jake L., Shengwei Hou, and Jed A. Fuhrman. \"Estimating maximal microbial growth rates from cultures, metagenomes, and single cells via codon usage patterns.\" Proceedings of the National Academy of Sciences 118.12 (2021): e2016810118.](https://doi.org/10.1073/pnas.201681011)|1. Growth rate of species listed in the original Vieira-Silva and Rocha dataset.<br> 2. All complete genomwe assenblies from RefSeq |The implementation is provided in an R package called **gRodon**|\n\n\n\n# General Growth Rate models\n\n\n## Exponential\n\n$$\nx(t) = x_0e^rt\n$$\n\nx<sub>0</sub> - Initial value <br> r - growth rate\n\n## Logistic \nc(t) is assumed to satisfy the following equation: <br>\n $$\n c'(t) = rc(t)[1 - \\frac{c(t)}{K}] \n $$\n <br> This equation has an explicit solution: <br>  \n $$\n c(t)= K/{1+[(K/c_0)-1]e^{-rt})}  \n $$\n  c(t) - expected cumulative cases <br> K - final size of the epidemic which c(t) approches\n\n## Richards\nc(t) in Richards satisfies <br>\n$$\n c'(t) = r c(t) \\biggl[1- \\biggl(\\frac{c(t)}{K} \\biggr)^a \\biggr] \n $$\n which has solution : <br>  \n\n$$ \nc(t) = \\frac{K}{ ( 1+ [(K/c_0)^a-1 )\\exp\\{ -r_0t/[1-(c_0/K)^a]\\} )^{1/a}} \n$$\n\n## Delayed Logistics\n\nWhile Logistic model is used to describe the cumulative incidence, this model is used to model the cumulative death\n\n$$\nd(t) = \\int_0^t c_{{}_{\\rm Log}}(s)e^{-m(t-s)}\\,ds \n$$\n\n- where c<sub>Log</sub>(t) is the solution to the logistic model\n- m is the rate of delay that is exponenetially distributed.\n\n*__In Logistic, Richards, Delayed Logistics the interval incidence is obtained by differencing cumulative expressions __*\n$$\nx(t) = c(t + \\Delta t)-c(t)\n$$\n*_where c(t) is cumulative incidence, and x(t) is interval incidence (typically daily or weekly)._* [1]\n## SEIR model (phenomenological model)\n\n# References\n[1]: <https://doi.org/10.1007/s11538-013-9918-2>\n\n\n","n":0.025}}},{"i":16,"$":{"0":{"v":"Wallinga_Lipsitch","n":1},"1":{"v":"\n## Motivation of the paper\n\n1. Observed r can be related to reproduction number : $R=1+rT_c$; Where $T_c$ is mean generation time. This is not the only expression there are many expressions that relate growth rate and reproductive number and each equation would result in a different estimate of reproduction number. Hence it is important to know which equation can be used for inferring reproductive number from the observed growth rate.\n2. [[Eurler lotka equation|Growth_Rate_Estimation.Glossary#eurler-lotka-equation]] is used as a start point  to examine the relationship between reproductive number and observed change in the number of cases.\n   \n## Deriving the Lotka-euler equation:\n1. This derivation is made on the assumption regarding human population (demographical and not epidemiological).\n2. Resent time is denoted as t=0, past time is denoted by negative number and future is represented using positive number. \n3. It is assumed that the population would displays exponential growth at a fixed growth rate and the age distribution of the population would not change over time.\n4. The equation is based on  two concepts - to get the total number of births in the year t.\n5. First : The sum of number of children born to mothers of all age at time t gives the birth at that time.\n6. second : The number of births to mothers of age a at time t is equal to the number of births at time t-a (the number of mothers, including those who have not survived) multiplied by the expected number of offspring per year for mothers of age a(simce time is involved we can call it  rate). Summing this over all possible mother's age at time t (first concept) gives the total number of births in the year t.\n7. $b(t)= \\int_{a=0}^\\infin b(t-a)n(a)da$ where b(t) is the birth rate of population at time t, n(a) rate of production of **female** offspring by a mother at age a. n9a) includes the fraction of individuals surviving at age a l(a) and the birth rate for mothers of age a m(a). n(a)=l(a)m(a)\n8. Since the population is growing exponentially, the rate can be given as  [[Exponential Function |Growth_Rate_Estimation.Glossary#exponential-function-and-e-eulers-number]]. The number of births at given time t is given as $b(t)=b(t-a)e^{ra}$ number of births at time t-a multiplied by the exponential growth rate $e^{ra}$. So combining the two equations $b(t)=\\int_{a=0}^\\infin b(t)e^{-ra}n(a)da$ cancelling b(t) on both the sudes we get \n   $1=\\int_{a=0}^\\infin b(t)e^{-ra}l(a)m(a)da$\n\n## A moment generating function expression for the reproductive number R\n1. It is seen that n(a) gives the rate of production of female offspring by a mother of age a. Integrating n(a) for the total lifespan gives the total number of female offspring produced by the mother over her lifespan. $\\R=\\int_0^\\infin n(a)da$.\n2. Normalising the rate $\\frac{n(a)}{\\int_0^\\infin n(a)da}=\\frac{n(a)}{R}=g(a)$ g(a) is the normalised rate distribution. If age is considered as the time since infection g(a) can be said as the probability distribution of the generation time. The equation can be rewriten as $\\frac{1}{R}=\\int_{a=0}^\\infin e^{-ra}g(a)da$\n3. ","n":0.046}}},{"i":17,"$":{"0":{"v":"Methods and R package for Reproduction number estimation","n":0.354},"1":{"v":"\n## A New Framework and Software to Estimate Time-Varying Reproduction Numbers During Epidemics - Anne Cori\n\n>EpiEstim R package\n\n### Crux of the paper\n\n+ Motivation of the paper:\n  1. To quantify the transmissibility - which can be measured by the reproduction number R, using a ready-to-use tool which uses incidence time series data\n  2. Methods based on fitting mechanistic transmission models to incidence data are often difficult to generalize because of the context-specific assumptions often made(e.g., presence/absence of a latency period or size of the population studied).\n  3. Though Wallinga and Teunis method is generic it is based on the probabilistic reconstruction of transmission trees and on counting the number of secondary cases per infected individual. $R^c$ is estimated for each time step, if the time step is too small like if the time step is per day  then it would make the curve very swiggly. If the time step is one serial interval then we'll have a smoothened curve - in such situations effectiveness of an intervention cannot be ascertsined through the $R^c$ value. If this curve is smoothened by external means then it would be sensitive to smoothing parameters.\n  4. Cohort reproduction number or case reproduction number  $R_t^c$- it is which is affected by intervention methods and so. This can be calculated only retrospectively. Wellinga-Teunis tries to estimate this cohort reproductove number. This method is right [[Censored|Growth_Rate_Estimation.Glossary#censoring-rightleft]]. Since this method estimates the R at particular time t based on the data received after t, at the end of time series the estimate artefactually decrease to zero.\n  5. $R_t^c$ can be measured only retrospectively whereas $R_t$ is based on the assumption that the reproductive number is constant. $R_t$ is easier to estimate and there is a sharp change in trend in $R_t$ reflecting the impact of the intervention whereas its not so in $R_t^c$.\n  \n  > The aim of the study was to develop a generic and robust tool for estimating the time-varying reproduction number, similar in spirit to earlier methods, but implemented with ready-to-use software\n\n+ Intuition of the model\n    1. Reproductive number at time t can be found with the incidence at time t and total infectiousness of the infected individuals at time t. But the the whole point is to predict the reproductive number.\n    2. A bayesian frame work is used for finding the Reproductive number. The likelihood of incidence given the reproductive number is easier to estimate and fit rather than finding the reproductive number given the incidnece. \n    3. To capture the proper trend in the Reproductive numbers at various time step, a time window is deployed. The length of the window is chosen in such a way that there is not too much statistical noise and there is no excessive smoothning.\n    4. In each time step t Reproduction number is calculated on a time window of size $\\tau$ endinf at t.\n    5. It is not an ideal scenario to know the time of infection, what is usually observed is the symptom onset. So the estimation is approximated using the serial interval and not the generation time. In disease like SARS and smallpox, the infectiousness starts only around the time of symptom onset. In such cases serial interval and generation time are identical.\n\n### Limitations\n\n1. unavailability of data regarding serial interval at the beginning of the pandemic\n2. Assumes all the cases after the first set of primary cases are local and not imported.\n\n### Model:\n[From Supplementary material](../Reference_papers/Cori_supp.pdf)\n\n+ Assumption: Distribution of infectiousness is independent of calander time. There are no import cases - all the primary and seconday infections belong to incidence time series. The proportion of asymptomatic cases anbd reporting rate are constant. The incubation time is constant.\n+ The transmission is modelled through [[Poisson Distribution|Growth_Rate_Estimation.Glossary#poisson-distribution]]\n+ Consider someone being infected at time step t-s. The rate at which this person would bring about new infections is said to be equal to $R_tw_s$ where $R_t$ is the [[Instantaneous reproductive number (also known as effective growth number)|Growth_Rate_Estimation.Glossary#reffective-reproduction-number]] which is the average number of secondary cases that each infected individual can cause if the conditions remained as in t. And $w_t$ is said to be the probability distribution of the infectiousness profile after infection - this depends on the biological factors such as pathogen shedding or symptom severity - an individual will be more infectious at time s (time since infection) when $w_s$ is larger.\n+ $w_s$ is approximated using serial interval distribution. Because $w_s$ and serial interval distribution would tell the  probability of transmissibality at a particular time.\n+ $R_t$ can be estimated by the ratio of the number of new infections generated at time step t, $I_t$, to total infectiousness of infected individual at time t. But we dont know incidence at time t either. So we do all these calculations.\n+ The total number of the infected individual at time t is the sum of indidence at all time steps from s to t  $I_{t-s}$multipled with corresponding probabitlity distribution of infectiousness $w_s$ which is more like a weighted sum. This weighted sum is multiplied with $R_t$ to get the average number\n+ Therefore $R_t\\sum_{s=1}^t{I_{t-s}w_s}$ is the mean of the poisson distribution.\n+ The likelihood of $I_t$ is given by poisson distribution \n  $$$\\\\\n  P(I_t|I_0,....I_{t-1},w,R_t)=\\frac{(R_t\\wedge_t)^{I_t}e^{-R_t\\wedge_t}}{I_t!}\\\\\n  \\wedge_t=\\sum_{s=1}^tI_{t-s}w_s\\\\  \n$$$\n\n > Poisson distribution: If $\\lambda =mean$ then the pdf of Poisson distribution is $P(X=k|\\lambda)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$\n\n+ Similarly if we assume that the transmissibility is constant over a time period of $[t-\\tau +1,t]$ (that is if we want to estimate $R_10$ and $\\tau=3$ then $R_10$ would be estimated on the interval [8,10] days)  and is measured by the Reproductive number $R_{t,\\tau}$ then the likelihood of incidence for $I_{t-\\tau +1}...I_t$ conditioned on previous incidence is\n$$$\n  P(I_{t-\\tau +1}...I_t|I_0....I_{t-\\tau},R_{t,\\tau},w)=\\prod_{s=t-\\tau +1}^t\\frac{(R_{t,\\tau}\\wedge_s)^{I_S}e^{-R_{t,\\tau}\\wedge_s}}{I_s!}.\n$$$\n\nNow we can use the bayessian inference with [[gamma|Growth_Rate_Estimation.Glossary#gamma-distribution]] prior with (a,b) as parameters for $R_{t,\\tau}$ to get the posterior joint distribution of $R_{t,\\tau}$\n$$$\\\\\nP(I_{t-\\tau+1},...,I_t,R_{t,\\tau}|I_0,...,I_{t-\\tau},w)=P(I_{t-\\tau+1},...I_t|I_0,..I_{t-\\tau},w,R_{t,\\tau})P(R_{t,\\tau})\\\\\n=(\\prod_{s=t-\\tau+1}^t\\frac{(R_{t,\\tau}\\wedge_s)^{I_S}e^{-R_{t,\\tau}\\wedge_s}}{I_s!})(\\frac{R_{t,\\tau}^{a-1}e^{-\\frac{R_{t,\\tau}}{b}}}{\\Gamma(a)b^a})\\\\\n=R_{t,\\tau}^{a+\\sum_{s=t-\\tau+1}^tI_S-1}e^{-R_{t,\\tau}(\\sum_{s=t-\\tau+1}^t\\wedge_s+\\frac{1}{b})}\\prod_{s=t-\\tau+1}^t\\frac{\\wedge^{I_s}_s}{I_s!}\\frac{1}{\\Gamma(a)b^a}\\\\\n\\propto R_{t,\\tau}^{a+\\sum_{s=t-\\tau+1}^tI_S-1}e^{-R_{t,\\tau}(\\sum_{s=t-\\tau+1}^t\\wedge_s+\\frac{1}{b})}\\prod_{s=t-\\tau+1}^t\\frac{\\wedge^{I_s}_s}{I_s!}\n$$$\n\n+ From above, it is shown that the posterior distribution of $R_{t,\\tau}$ is a gamma distribution with parameters $(a+\\sum_{s=t-\\tau+1}^tI_S,\\frac{1}{\\frac{1}{b}+\\sum_{s=t-\\tau+1}^t\\wedge_s})$ Altering the values of the parameters we can obtain the desired characteristics of the posterior $R_t$.\n+ The mean, variance and coefficient of variance of this distribution is \n$$$\\\\\n\\mu=\\frac{(a+\\sum_{s=t-\\tau+1}^tI_s)}{(\\frac{1}{b}+\\sum-{s=t-\\tau+1}^t\\wedge_s)}\\\\\n\\sigma^2=\\frac{(a+\\sum_{s=t-\\tau+1}^tI_s)}{(\\frac{1}{b}+\\sum-{s=t-\\tau+1}^t\\wedge_s)^2}\\\\\nCV=\\frac{1}{\\sqrt{a+\\sum_{s=t-\\tau+1}^tI_s}}\\\\\n$$$\n **How is cv calculated** : consider parameters be $\\alpha$ and $\\frac{1}{\\beta}$ respectively. Then \n $$$\\\\\n\\mu=\\frac{\\alpha}{\\beta}\\\\\n\\sigma^2=\\frac{\\alpha}{\\beta^2}\\\\\ncv=\\frac{\\sigma}{\\mu}=\\frac{\\sqrt{\\frac{\\alpha}{\\beta^2}}}{\\frac{\\alpha}{\\beta}}=\\frac{1}{\\alpha}\n$$$\n\n+ Estimate of $R_t$ is dependent on the time window. Choosing a small $\\tau$ would give way to detect rapid changes in the transmission but would lead to more noise in the data, while choosing a large $\\tau$ would result in more smoothing.\n+ The CV of the posterior distribution of $R_{t,\\tau}$ allows a way to link the CV and number of incident cases in the time window. A predeterminded CV<sub>treshold</sub> would allow to determine the minimium number of incident cases in the time window considered.\n  $$$\\\\\n  \\sum_{s=t-\\tau+1}^tI_s\\ge\\frac{1}{CV_{treshold}^2}-a\n  $$$\n  This a can be determined from the prior CV. Say the prior CV is $\\frac{1}{\\sqrt{a}}$ then if a prior cv of 2 is required \n  $$$\\\\\n  CV_{prior}=\\frac{1}{\\sqrt{a}}\\\\\n  \\sqrt{a}=\\frac{1}{CV_{prior}}\\\\\n  a=\\frac{1}{CV_{prior}^2}\n  $$$\n\n  The following table is derived with prior CV and aimed posterior CV to obtain the incidence in a time window.\n![CV and incidence](assets/images/CV_incidence.png)\n\n+ This table can be used to determine when is it right time to start estimating R based on the required precision.\n+ The serial interval is used as an approximation of $w_s$. The distribution of the serial interval is not well characterised at the beginning of the epidemic. A sampling method is described in the paper to account for the uncertainities in the serial interval.\n\n> For instances where there was poor documentation about serial interval, it is assumed to be gamma distributed  while its mean and variance take up values according to [[Truncated Normal Distribution|Growth_Rate_Estimation.Glossary#truncated-normal-distribution]]. The sampled mean and the standard deviation are chosen in such a way that the mean is greater than the standard deviation. This ensures a bell shaped pdf curve with Serial interval as zero when t=0. For each pair $(\\mu_{SI},\\sigma_{SI})^k$, for each time window $\\tau\\space n=1000$ R is sampled in its posterior distribution conditional on $(\\mu_{SI},\\sigma_{SI})^k$. So for each time window we'll have $n\\times n_{SI}=1,000,000$ joint posterior distribution of R.\n\n> In cases where the symptom onset denotes the start of infectiousness serial time and generation time are identical.\nIn such a case the difference between time of symptom onset in the primary and secondary cases is the incubation time.\n\n**Discretization of serial interval distributions:**\nThe serial interval distribution that is fitten to the events of notable infections in an small environment like household is a continuous distribution. The incidence data that is obtained is always discrete, So a formula to discretize serial interval is proposed in the paper. Web appendix 11, not very intuitive.\n\n## **The $R_0$ Package : A tool box to estimate the reproduction numbers for epidemic outbreaks - Thomas Obadia:**\n\n+ It is more like a review of methods used in the package to estimate the initial growth rate and serial interval distributions.\n+ **est.GT** is the fuction that is provided to estimate the serial interval distribution from a sample of observed time intervals between symptom onsets in primary cases and secondary cases by maximum likelihood.\n+ Incidence data is provided either as a vector of dates of onset or vector of incidence counts along with initial date or time step.\n+ All the methods except the [[attack Rate|Growth_Rate_Estimation.Glossary#attack-rate]] needs input of epidemic curve, generation time distribution.\n+ **estimate.R** is used to estimate R with either of the methods described below.\n+ **sensitivity.analysis** computes the the [[R-squared|Growth_Rate_Estimation.Glossary#r-squared]] over a range of time periods chosen by the user. For the estimation of Reproduction number using Exponential growth rate methods and Maximum likelihood it is necessary to do the calculation on the exponential growth of the epidemic.\n+ When a best fitting time period is chosen by using the **sensitivity.analysis** function the variability between the Reproductive number estimates given by exponential growth model and maximum likelihood model is minimal.\n+ The estimation of R is also affected by the chosen generation time distribution.\n+ All the methods tends to be less biased when the aggregation is less that the generation time. Very small aggregation step would result in gaps (0 observations).\n+ It has been previously reported that aggregation of time period  equal to mean of generation time is ideal for the estimation\n  \n### **Methods to estimate Reproduction rate and the associated assumptions:**\n+ **Attack Rate:**\n  1. It is the percentage of population eventually infected. This is used in the **_SIR model_** and it is linked to the basic reproduction number. \n$$$\\\\\nR_0=-\\frac{ln(\\frac{1-AR}{s_0})}{AR-(1-S_0)}\n$$$\n$S_0$ initial percentage of suceptible population.\n[[Confidence interval|Growth_Rate_Estimation.Glossary#confidence-interval]] of [[Attack Rate|Growth_Rate_Estimation.Glossary#attack-rate]] is calculated as $CI(AR)=AR\\mp 1.96*sqrt(AR*(1-AR)/n)$\n **Assumptions:**\nHomogenous mixing, closed population and no intervention during outbreak\n  2. This method can be used only at the end of the epidemic that had no intreventions set up.\n  3. Therefore it is used to estimate R in closed settings like epidemic in schools.\n\n+ **Exponential Growth Rate:**\n  1. Exponential growth rate at the early phase of an outbreak can be linked to initial reproduction ratio r.\n  2. Reproduction number is computed as $R=\\frac{1}{M(-r)}$ where M is the [[Moment Generating function|Growth_Rate_Estimation.Glossary#moment-generating-function]] of generation time distribution. This is summarized by Wallinga & Lipsitch.\n  3. [[Confidence interval|Growth_Rate_Estimation.Glossary#confidence-interval]] is computed from the $\\frac{1}{M(-r)}$ formula with bounds on r from the poisson regression.\n  + **Condition:** The chosen period should contain exponential growth of the epidemic. This exponential growth period can be chosed using the [[R-squared|Growth_Rate_Estimation.Glossary#r-squared]] statistic\n  \n+ **Maximum Likelihood estimation(ML):**\n  1. Model Proposed by white and Pagano.\n  2. **Assumption:** Number of secondary cases caused by primary case is poisson distributed (since it deals with the count of cases per primary case), with expected value R (the average number of secondary cases caused by the primary case.).\n  3. Given the observation of incident cases over consecutive time units, generation time distribution w, R is estimated by maximising the log-likelihood  $\\\\LL(R)=\\sum_{t=1}^Tlog(\\frac{e^{-\\mu_t}\\mu_t^{N_t}}{N_t!})\\space where\\space \\mu_t=R\\sum_{i=1}^tN_{t-i}w_i$\n  4. Generation time shoudl be discretized.\n  5. [[Confidence interval|Growth_Rate_Estimation.Glossary#confidence-interval]] is achieved by profiling the likelihood.\n  + **Condition:** The chosen period should contain exponential growth of the epidemic.This exponential growth period can be chosen using the [[R-squared|Growth_Rate_Estimation.Glossary#r-squared]] statistic.\n\n+ **Sequential Bayesian Method(SB):**\n  1. Sequential estimation of initial reproduction number.\n  2. Relies on the approximation of SIR model where the incidence at time t+1 denoted as N(t+1) is poisson distributed with mean $N(t)e^{\\gamma(R-1)}$ where $\\frac{1}{\\gamma}$ is the average duration of infectious period.\n  3. [[Confidence interval|Growth_Rate_Estimation.Glossary#confidence-interval]] is achieved by a cumulated sum of the R posterior distribution and corresponds to the 2.5% and 97.5% tresholds.\n\n> My interpretation of the mean: there is an average exponential growth in the incidence at a rate of $\\gamma(R-1)$ where (R-1) is the average number of secondary cases and the $\\gamma$ can be number of primary cases ($\\\\\\frac{sum\\space of\\space infection\\space time\\space durations}{number\\space of\\space infections}=Average\\space infectious\\space period\\\\\\frac{sum\\space of\\space infection\\space time\\space durations}{Average\\space infectious\\space period}=number\\space of\\space infections$) Multiplying it with N(t) would give the mean for until time step t.\n\n   This Bayesian inference framework is used in this model. The idea is to use the probability distribution of R calculated on the data set $N_0,...N_t$ as prior to calculate the postrior distribution \n   $$$\\\\\n   P(R|N_0,..N_{t+1})=\\frac{P(N_{t+1}|R)P(R|N_0,...N_t)}{P(N_0,..N_{t+1})}\n   $$$\n\n  + **Assumption:** Random mixing in the population\n\n+ **Estimation of time dependent reproduction numbers(TD):**\n  1. Proposed by Wallinga and Teunis\n  2. Reproduction number is computed by averaging over all transmission at same level in a transmission network.\n  3. The probability that the case i at time $t_i$ is infected by case j that has time onset $t_j$ is given by $P_{ij}$\n  4. $$$\\\\\n  P_{ij}=\\frac{N_iw(t_i-t_j)}{\\sum_{i\\ne k}N_iw(t_i-t_k)}\n  $$$\n  5. The effective reproduction number which is the average number of secondary cases that a primary case can cause is given by the expectation number $R_j=\\sum_i p_{ij}$ This is averaged as $R_t=\\frac{1}{N_t}\\sum_{t_j=t}R_j$ over all cases with same date of onset.\n  6. Generation time should be discretized\n  7. Imported cases can also be accounted\n  8. [[Confidence interval|Growth_Rate_Estimation.Glossary#confidence-interval]] is computed by multinomial simulations at each time step with expected value of R.\n\n## Things to note\n\n1. In the situation that the epidemic is not observed from the begining there are possibility of missing few index cases, this might lead to the over-estimation of initial R because of more secondary infections that would have been noted. In case of maximum likelihood method using the assumption of constant reproductive number is used as a corrective measure for this issue.\n2. No methods accounts for under reporting. \n3. Delay in reporting would affect the ML and TD methods as it would bias the incidence. It would be possible to correct this if the reporting delay is known.\n4. Importation cases could lead to overestimation of reproduction ratio. TD and ML can satisfactorily correct this\n5. Combination of reproduction number magnitude, mean generation time duration and aggregation detail is important for a right estimation.\n\n## **Different Epidemic Curves for SARS Reveal similar Impacts of Control Measures - Wallinga and Teunis:**\n\n**Motivation**\n\n1. The epidemic curves of SARS from regions where the disease started at the same time and the interventions were given at the same time. Despite the similarities the epidemic curves were distinct in the temporal patterns in the number of SARS cases.\n\n**Data**\n\n   1. Observed epidemic curves: Number of reported cases by the date of symptom onset. Basically the observed incidence given by days.\n   2. Observed Distribution of generation time/ serial time\n\n**Estimation of Reproduction numbers - Likelihood based estimation procedure**\n\n1. Since the contact network is usually not known a likelihood method is used to estimate who infected whom from observed incidence data. \n2. A pair of cases are considered while estimating the likelihood to avoid computational complexity.\n\n**Estimation procedure:**\n  **Infection Networks:**\n  \n  1. Considering outbreak of **n** Reported cases with **q** cases being imported, so **n-q** cases has their primary cases among the reported n cases. Each case is indexed with i : $i\\isin \\{1,..n\\}$. This can be represented using a directed graph with nodes as the cases and edges showing the transmissions.\n  2. This graph can be represented as a vector **_v_** where the **v(i)** would denote the label primary case that infected the case with label **i**. **v(i)=0** for imported cases.\n  3. Entire set of all the infection network is represented as **V**\n  4. Each of the **n-q** cases can be possibly caused by any of **n-1** primary cases - since a case cannot infect itself we do a minus 1. Hence we get $(n-q)^{(n-1)}$ different network structures.\n  5. Note that the set V includes network structures with cycles and that such structures cannot represent transmission between cases.\n  6. Transmission of case j to case i is independent of transmission : case j to case k.\n  7. I assume that the labels of cases are mostly the time of infection reported.\n\n  **Likelihood inference for infection networks**\n  1. Likelihood that a particular network **v** underlies the the observed epidemic curve **t** (incidence data). \n  2. **Assumption**: The infection occured only among the n cases.\n  3. $w(\\tau|\\theta)$ is the probability density function for generation interval : $\\tau$ is the generation interval and $\\theta$ are the parametres of the distribution. $w(\\tau|\\theta)=0$ for $\\tau<0$ this ensures that the network with cycles have zero probability associated to it.\n\n  **Likelihood Functions:**\n\n  1. The likelihood of infectious network **v** and Generation time distribution with parameter $\\theta$ for given incidence data (epidemic curve t) equals to the probability of the epidemic curve distribution given the infectious network and parameters of distribution.\n\n  > I assume the difference in the time onset of incidence/symptom data would also follow the distribution of the generation time - certain time intervals in the incidence cases can have higher cases in accordance to the generation time.\n\n  $$$\\\\\nL(v,\\theta|t)=\\prod_{i=1}^{i=n-q}w(t_i-t_{v(i)}|\\theta)\n  $$$\nCalculating the Likelihood for sets of infectious network V. This requires a weight function $c(v|\\theta)$ for each of the networks in V. The likelihood over all networks is therefore\n$$$\\\\\nL(V,\\theta|t)=c\\sum_V \\prod_{i=1}^{i=n-q}w(t_i-t_{v(i)}|\\theta)=c\\prod_{i=1}^{i=n-q} \\sum_{j=1,j\\ne i}^{j=n}w(t_i-t_j|\\theta)\n  $$$\n  for each i in the n-q nodes j primary cases which belongs to N nodes except the self is considered.\nLikelihood over all the infectious network which has case k infected by case l (this transmission is explicitely considered)\n$$$\\\\\nL(V_{(k,l)},\\theta|t)=cw(t_k-t_l|\\theta)\\prod_{i=1,i\\ne k}^{i=n-q} \\sum_{j=1,j\\ne i}^{j=n}w(t_i-t_j|\\theta)\n  $$$\n> The pobability density function is multiplied on different i (cases) becase $t_i-t_{v(i)}$ are independent pairs while the different primary cases that can infect a case i is mutually exclusive and hence it is added.\n\n**Estimation**\nThe relative likelihood of case k been infected by case l is given as \n$$$\\\\\nP_{(k,l)}=\\frac{L(V_{(k,l)},\\theta|t)}{L(V,\\theta|t)}=\\frac{cw(t_k-t_l|\\theta)\\prod_{i=1}^{i=n-q} \\sum_{j=1,j\\ne i}^{j=n}w(t_i-t_j|\\theta)}{c\\prod_{i=1}^{i=n-q} \\sum_{j=1,j\\ne i}^{j=n}w(t_i-t_j|\\theta)}=\\frac{w(t_k-t\n_l|\\theta)}{\\sum_{m=1,m\\ne k}^{m=n}w(t_k-t_m|\\theta)}\n$$$\n\nThe distribution of the effective reproduction number for case l is $R_l\\sim\\sum_{k=1}^{k=n-q}Bernoulli[p_{(k,l)}]$ with expected value\n$E(R_l)\\sim\\sum_{k=1}^{k=n-q}p_{(k,l)}$\n\n**Simultaneous estimation of parameters v and $\\theta$:**\nWhen we have the data of transmission of infection between some pairs of cases, it is possible to infer infection network (v) and generational interval parameter ($\\theta$) by maximising the likelihood using the [[Expectation maximization algorithm|Growth_Rate_Estimation.Glossary#expectation-maximization-algorithm]]. $\\\\L(V_{(k,l)},\\theta|t)=c(v|\\theta)\\prod_{(k,l)}w(t_k-t_l|\\theta)c\\prod_{i=1,i\\ne k}^{i=n-q} \\sum_{j=1,j\\ne i}^{j=n}w(t_i-t_j|\\theta)$\n(k,l) are all observed cases where k is infected by l.\n\nThe effective reproduction number for case j is the sum over all cases it can cause $R_j=\\sum_ip_{ij}$\n\n - It is claimed that the effective reproduction numbers for infectious diseases at a finer temporal resolution under more general assumptions than was previously possible.\n  \n### **Regarding the performace of the model:**\n\n1. The model allows for a variable effective reproduction number Rt as a function of symptom onset data t, and the model parameters are estimated from observations on the SARS epidemic in Singapore\n2. For simulated outbreaks the estimations were close to the actual reproductive number and for smaller outbreaks the estimates were below the actual reproduction number that was used in the simulation model. So taking a smaller epidemic size and a shorter epidemic duration to estimate the R is not recommended. \n3. on average they deviate less that 15% from actual reproduction number.This is also for the scenario of incomplete reporting.\n4. Evaluating the effect of time of implementation of control measures on the epidemic size and durations\n![How is it done](assets/images/Simulated_epidemics.png)\n\n**Results**\n\n1. This apparent difference in epidemic curves arises because chance effects, such as the occurrence of a rare “super-spread event,” leave a lasting trace on the epidemic curve.\n2. The average effective reproduction number etimated by this methos is more precise\n\n## **Improved inference of time-varying reproduction numbers during infectious disease outbreaks - Thomson:**\n\n### Motivation:\nExtension of the statistical framework of [[Anne Cori et al.,|growth_rate_estimation.Methods to estimate R#a-new-framework-and-software-to-estimate-time-varying-reproduction-numbers-during-epidemics---anne-cori]] to estimate $R_t$. The serial interval is derieved from the known pair of primary and secondary cases. The uncertainity in the serial interval is also fully accounted. The method also allows incorporation of imported cases. The methods are implemented in EpiEstim2.2\n\n### Methods:\n\nTwo step procedure - Step 1: Estimation of serial interval from observed primary and secondary cases. Step 2: Estimation of $R_t$\njointly from incidence data and from posterior distribution of serial interval that was infered from the first step.\n\n**Estimation of Serial interval:**\n\n1. During a outbreak symptom onset in primary and secondary cases in household and hospitals are recorded as [[Interval Censored|Growth_Rate_Estimation.Glossary#censoring-rightleftinterval]] data. [[Interval censored |Growth_Rate_Estimation.Glossary#censoring-rightleftinterval]] data accounts for the lack of knowledge of precise timing of symptom apprearance.\n2. The data was used to perform Bayesian parametric estimation of serial interval distribution using the data augmented Markov chain Montecarlo.\n\n**Estimation of Reproduction number:**\n\n1. The total number of incident cases at timestep t given as $I_t$ is the sum of imported and local cases. $I_t=I_t^{local}+I_t^{imported}$. It is assumed that the local and imported cases can be distinguished by epidemiological investigations. So at each step $I_t^{local}, I_t^{imported}$ are observed. \n2. Following [[Anne Cori et al.,|growth_rate_estimation.Methods to estimate R#a-new-framework-and-software-to-estimate-time-varying-reproduction-numbers-during-epidemics---anne-cori]] $R_t$ is defined as ratio of number of new locally infected cases to the total infection potential across all the infected individual at time t. The total infectious potential is calculated as:\n  $$$\\\\\n  \\wedge_t(w_s)=\\sum_{s=1}^t(I_{t-s}^{Local}+I_{t-s}^{imported})w_s=\\sum_{s=1}^tI_{t-s}w_s$$$\n3. The Equations are more similar to the equations in the Cori paper section but there are sampled serial interval distributions which are included to get the posterior probability of reproduction number\n\n\n### Doubts\n1. How is $R_t$ the ratio of number of new infections generated at time step t, $I_t$​, to total infectiousness of infected individual at time t? - Anna Cori paper","n":0.017}}},{"i":18,"$":{"0":{"v":"R_packages","n":1},"1":{"v":"## **EpiEstim package**\n[EpiEstim Demonstration](https://mrc-ide.github.io/EpiEstim/articles/short_demo.html#estimating-r-accounting-for-uncertainty-on-the-serial-interval-distribution)\n\n## Methods:\n\n1. **Parametric_si**: mean and sd of the si are given. The Estimation method uses an offset gamma distribution with provided parameters to estimate R.\n2. **Non parametric Serial Distribution**: The serial distribution is entirely known. Using the function discr_si(number of data points, mean, standard deviation) a descritised serial distribution datapoint from a distibution with the desired mean and sd can be obtained\n3. **uncertain_si** : While estimating R with method 'uncertain_si', n pairs of means and standard deviations are sampled. These means and standard deviations are sampled from  a [[Truncated Normal Distribution|Growth_Rate_Estimation.Glossary#truncated-normal-distribution]]. The means are derived from a truncated normal distribution with mean mean_si, standard deviation std_mean_si, minimum mean min_mean_si, maximum mean max_mean_si. The standard deviations are derieved from [[Truncated Normal Distribution|Growth_Rate_Estimation.Glossary#truncated-normal-distribution]] with mean - std_si, standard deviation - std_std_si, minimum mean min_std_si, maximum mean - max_std_si.\n4. **si_from_data**: Serial interval distribution is estimated using MCMC from the interval censored data. New data can be included and the serial interval can be updated.\n\n### Doubts EpiEstim:\n\n1. how does this command thats a function belonging to estimate_r is invoked?  -  plot(r_parametric_si). This looks like a regular plot command.\n\n\n\n### Important Reference:\n\n[Plot output of estim_r](https://www.rdocumentation.org/packages/EpiEstim/versions/2.2-3/topics/plot.estimate_R)\n[Discretizing serial interval](https://www.rdocumentation.org/packages/EpiEstim/versions/2.2-4/topics/discr_si)\n[Make config](https://www.rdocumentation.org/packages/EpiEstim/versions/2.2-4/topics/make_config)\nWhile estimating R with method 'uncertain_si', then n pairs of means and standard deviations are sampled. These means and standard deviations are sampled from  a truncated normal distribution. The means are derived from a truncated normal distribution with mean mean_si, standard deviation std_mean_si, minimum mean min_mean_si, maximum mean max_mean_si. The standard deviations are derieved from truncated normal distribution with mean - std_si, standard deviation - std_std_si, minimum mean min_std_si, maximum mean - max_std_si.\n\n## **R_0 package**\n[Manual](https://cran.r-project.org/web/packages/R0/R0.pdf)\n\n## Doubts_R0_package\n\n\n\n\n### Functions/ commands that are being used in the package\n\n#### **check.incid**\n\nThis function is called internally by the estimation methods make the input incidence and dates data comatible to estimation methods.\n\n   1. Takes in incidence object(vector/list) and vector of   dates or the start date and the size of the time step.\n   2. Returns incidence and the dates in as double. \n   3. Incidence data should not contain negative or missing values.\n   4. Incidence data and time vector should have the same length.\n\n#### **est.GT**\n\n1. Finding best fitting GT distribution for the given serial interval.\n2. Serial interval is either provided as time lag between infector infectee pair. Or as two vectors one describing the date of onset of symptom onset in infector and the other is the date of symptom onset in infectee.\n3. This function returns the name of the best fitting distribution along with the parameters like mean and sd.\n4. It also return mean and sd of the descritized GT along with I assume few data point in the discritized distribtuion.\n\n#### **est.R0.AR**\n\n1. Estimates the Reproduction number based on the [[attack rate|Growth_Rate_Estimation.Glossary#attack-rate]] alone (Initial proportion of the population considered susceptible has a default value of 1)\n 2. Estimates is also done using population size and the incident cases - either given as a vector or a total count.\n3. If Population size is given the confidence intervals are computed.\n\n#### **est.R0.EG**\n\n1. This function needs the epidemic curve data, generation time distribution, begin and end time of the computation. \n2. An argument reg.met which is in default poisson is used to fit the incidence rate data (epidemic curve) and estimate r.\n\n#### **est.R0.ML**\n\n1. Needs the input of epidemic curve, Generation time distribution, range in which the maximum should be looked for. \n2.  If the generation time distribution is not known agrument unknown.GT is set true. Nevertheless the mean and sd of the GT should still be given. This values will be used as a starting value for the optimization routine.\n\n#### **est.R0.SB**\n1. Epidemic curve, generation time distribution are fed in to the model.\n2. Estimate of R at every sequential time step is the output.\n   \n#### **Estimation of time dependent reproduction number:**\n\n1. The incidence data is used to get the initial number of cases. Generation time interval is computed using generation.time. \n2. Agregating the initial data by a time unit is possible with method smoot.RT.\n\nApart from these methods there are also commands and options to simulate an epidemic - generates an epidemic curve with specified distribution and reproduction number. **sim.epid.indiv**,**sim.epid**\n\n## EpiEstim vs R_0 package\n\n1. EpiEstim - Only intstantaneous Reproduction number. While R_0 is for Basic Reproduction number and instantaneous reproduction number. But for maximum likelihood method only one value of R is estimated with the confidence interval.\n2. Epi_estim methods : differ only according to the inputs for the serial interval - parametric, non parametric, serial interval from the data. While R_0 packages differ on the method employed to find the Reproduction number.\n3. EpiEstim uses estimate_R with arguments t_start,t_end in the config to specify the start and end time of each window. While the begin and end arguments in the  est.R0.(EG/ML/SB/TD) is used to say the start and end time of the estimation. ","n":0.036}}},{"i":19,"$":{"0":{"v":"SARS_Cov2_notes","n":1},"1":{"v":"\n\n## Questions to ponder on:\n\n1. Will there be any difference in the charaacteristics of the transmissabiity variables of epidemic and pandemic\n2. \n## **Facts on SARS-CoV2:**\n\n- The SARS-CoV-2 virus accumulates approximately 24 point muta- tions per year, or 0.3 mutations per viral generation [3]\n\n## ** Factors to consider when modelling the epidemiology of SARS Cov2 **:\n\n   - Asymptomatic insdividuals - who may or may not be infectious to others\n    - Pre-symptomatic infectious period\n    -  Impact of partial or full (‘lock down’) isolation \n    -  known unknown’ is the duration of immunity post recovery\n    -  it is not clear if those reinfected are again infectious to others or exhibit symptoms of infection that result in measurable morbidity\n    - ‘unknown unknowns’ (meaning unmeasured parameters and unknown pathways of infection, transmission and disease [1]\n\n\n## ** Importance of Reproduction Number:**\n\n[[Reproduction Number:|Growth_Rate_Estimation.Glossary#reproduction-number]]\n\n  - R<sub>0</sub> and R<sub>t</sub> are important measure of the progression of an epidemic\n  - It is used for the policy formulation.\n  - The value of R matters – not just whether it is greater or less than 1 – but because the value of R when greater than unity tells you what proportion of new infections you need to prevent in order to go from increasing incidence to stable or decreasing incidence.\n  - In addition, the magnitude of R<sub>0</sub> [[(Basic Reproduction Number):|Growth_Rate_Estimation.Glossary#r0basic-reproduction-number]] also provides information on what level of herd immunity will drive the value of R to less than unity such that the infection cannot persist.\n  - This gives the target for vaccination programmes of what fraction of the community to immunise. As a rough approximation, the expression p=1-1/R<sub>0</sub> gives the critical proportion (or percentage) p that must be immune if transmission is to be halted. For a value of 2.5 as recorded in Wuhan in the early stages of the epidemic, this critical proportion is 0.6 or 60%. That is : 1 primary infection causes 2.5 secondary infections. So 1/2.5 primary infection causes 1 secondary infection. So to get a 1 as secondary infection there must be only 1/2.5 primary infection which means 1-1/2.5 should be immunised which is 60%.[1]\n  \n## **Dynamics of Serial/Generation interval**\n\n[[Generation Time|Growth_Rate_Estimation.Glossary#generation-time]]\n\n[[Serial interval|Growth_Rate_Estimation.Glossary#serial-interval]]\n\n\n\n - Serial interval in the case of COVID-19 has less relevance given that many infections especially in the young do not seem to generate marked\n    and easily identifiable symptoms.\n  \n  - The interventions that are put into places will affect the dynamics of both serial interval and generation time.\n    1. shorter generation times early in the epidemic,\n  and longer ones as the epidemic is declining\n    2. For a highly variable incubation period there may be negative serial intervals, which may\n    be misinterpreted as the wrong direction of transmission.If the wrong direction of transmission is assumed, contact tracing efforts may stop prematurely and miss new infections that then may lead to further uncontrolled transmission events.[1]\n\n## **Relationship between Generation time/ Serial interval, epidemic growth and Reproduction number**\n\n\n\n       r = (R0-1)/Ƭ \n\n  To explain the relationship between R and time an comparison is provided by HIV, which has an R<sub>0</sub> of around 2 in some populations, and influenza, which has an R<sub>0</sub> around 1.329, the most important being the reproduction number R, but the timescale from one infection to the next is days for influenza but months or years for HIV.[1]\n\n  [[Epidemic Growth rate|Growth_Rate_Estimation.Glossary#epidemic-growth-rate]]\n\n  ## **Using Epidemic growthrate**\n\n  Epidemic growth rate is a measure of the speed of epidemic growth, conveying information about the time scale of disease spread. In contrast, R<sub>0</sub>is a pure number with no associated time scale; epidemics with the same R<sub>0</sub>\n can occur over vastly different time periods, ranging from days to years. Knowing the epidemic time frame can be critical for selection of disease control strategies. Secondly, r itself is independent of potentially uncertain knowledge about the generation interval distribution, and thus may be useful in comparing the severity of disease epidemics.[2]\n  Epidemic growth rate r itself can only be directly measured providing case reporting, hospital admissions, recorded deaths due to COVID-19 or serological data.\n  but when the main source\n of data is deaths other information is required such as the probability distribution of times from infection to death\n and the fraction who die from infection.[1]\n  \n## **Resources that can be used for the dissertation**:\n\n- [Achaiah, Nithya C et al. “R0 and Re of COVID-19: Can We Predict When the Pandemic Outbreak will be Contained?.” Indian journal of critical care medicine : peer-reviewed, official publication of Indian Society of Critical Care Medicine vol. 24,11 (2020): 1125-1127. doi:10.5005/jp-journals-10071-23649](https://www.ijccm.org/doi/pdf/10.5005/jp-journals-10071-23649)\n  \n<!--References-->\n  [1]: <./assets/Reference%20literature/set-covid-19-R-estimates.pdf> \n  [2]: <https://doi.org/10.1007/s11538-013-9918-2>\n  [3]: <https://doi.org/10.1038/s41586-021-04069-y>\n\n  \n  \n\n","n":0.036}}},{"i":20,"$":{"0":{"v":"Glossary","n":1},"1":{"v":"\n# **Epidemiological Terms**\n\n## **Reproduction Number:**\n  \n  The number reflects the infectious potential of a disease\n\n### **R<sub>0</sub>(Basic Reproduction Number):**\n\nThe expected number of secondary cases generated\nby an average infected person(typical primary case) throughout their infectious period in a wholly susceptible population - **_when the population is fully susceptible_**\n\n![Importance of R0](./assets/images/Importance%20of%20R0.png)\n\n### **Case Reproductive number or cohort reproductive number:**\nThe average number of secondary cases arising from a primary case infected at time t. This can be estimated only after time t. So this is mostly observed number.\n\n### **R(Effective Reproduction Number):**\n\nNumber of secondary infections generated from a population consisting of both **_naïve/susceptible and exposed/immune individuals_** and therefore will always be less than R0.\nThe effective reproduction number is also known as instantaneous reproductive number beacuse it is taken at a particular point of time as after the beginning of the endemic/pandemic.\n\n- #### **Backward looking R:**\n\n  R<sub>t</sub> estimated for the cases infected at the time of an intervention like lockdown. This is regarding the primary infection that cased the secondary infections which are currently prevailing when the intervention is introduced (takes pre intervention scenario into account)\n\n- #### **Forward looking R:**\n  \n  The infections that were prevailing at the time of introduction of intervention were considered as primary infection and the average number of secondary infections caused by these primary infections are taken as forward looking R. This is lower than the backward looking R as the consequence of the intervention.\n  \n[[Importance of Reproduction number | Growth_Rate_Estimation.SARS_Cov2_notes#importance-of-reproduction-number]].\n\n## **Epidemic Growth rate:**\n\n- Represents the rate at which number of new infections arises.It can be either positive or negative. It is dependent on the reproduction number and timescale between infections $r = (R_0-1)/Ƭ$. If R<sub>0</sub> is greater than 1 then there is an exponential growth rate. When R<sub>0</sub> < 1 the infection cannot be established in the population and dies out.\n  [[Relationship between Generation time/ Serial interval, epidemic growth and Reproduction number|Growth_Rate_Estimation.SARS_Cov2_notes#relationship-between-generation-time-serial-interval-epidemic-growth-and-reproduction-number]]\n- The instantaneous epidemic growth rate, **r<sub>t</sub>**, defined as the rate of change of the log‐transformed case incidence, has been proposed as a more informative and understandable measure of transmission dynamics. [5]\n- Growth rate is esstentially the rate of change of incidence.\n\n## **Seropositives:**\n\nShowing a significant level of serum antibodies, or other immunologic marker in the serum, indicating previous exposure to the infectious agent being tested.\n\n## **Generation Time:**\n\n  The generation time, Ƭ, for an infectious disease is the time between **_infection_** events in an infector-infectee pair of individuals.\n  It can be used to derieve the speed of the spread.\n  Measuring Generation time is challenging because it is unobserved. Hence is usually replaced with serial time.\n  However, ignoring the difference between the serial interval and generation time can lead to biased estimates of R.\n  At this early stage the instantaneous r of the exponentially growing epidemic curve, is approximately given by $r = (R_0-1)/Ƭ$\n  \n## **Serial interval:**\n\n  Serial intervals describe the average time between symptoms of infection in the primary infection to when the person he or she infects develops symptoms.\n  It is easier to measure than\n   the generation time as symptom onset is easier to identify through contact tracing studies than time of infection acquisition.\n\n## **The doubling time of the epidemic:**\n\nThe number of days or time units which leads to a doubling in cases. The doubling time dt in the early stages is therefore: dt = ln(2)/r.\nTo give a simple example, the doubling times of cases in the UK in the rapid growth phase of the epidemic in March 2020 before 'lock down', was of the order of 3 to 4 days30. Taking a value of 3.5, this gives an r estimate of 0.2 per day.\nThe doubling time is useful only at the start of epidemic.\nWhen the epidemic is in the decline stage halving time is used. It is the time required for the number of cases to halve and hence how rapidly or slowly the remaining cases will decline to eradication\n\n## **20/80 rule:**\n\nDefines that in many cases 80% of the transmission results from 20% of the infected in any one generation of infection spread.\n\n## **Viral fitness:**\n\nThe capacity of a virus (a serotype, clade, or variant) to become dominant in the field, relative to other serotypes, clades, or variants of the same virus has been defined as epidemiologic fitness\n![viral_fitness](assets/images/viral_fitness.png)\n\n[viral_fitness_reference](https://doi.org/10.1016/j.coviro.2012.07.007)\n\n## **Incidence vs Prevalence:**\n\nPrevalence differs from incidence in that prevalence includes all cases, both new and preexisting, in the population at the specified time, whereas incidence is limited to new cases only<br>\nPrevelance is calculated as:\n$$$\nPrevalance = \\cfrac{Number\\space of \\space cases\\space in\\space the\\space population\\space at\\space one\\space time}{total \\space population\\space at\\space that\\space timera}\n$$$\nIncidence is the number of new cases during a specified time period in a population at the same time.\nIncidence is calculated as:\n$$$\nIncidence = \\cfrac{New\\space cases\\space during\\space a\\space specified\\space time }{total\\space population\\space at\\space risk\\space at\\space that\\space period\\space of\\space time\\space}\n$$$\n[13]\n\n## **Cumulative Incidence:**\n\nCumulative incidence is the proportion of a population at risk that develops the outcome of interest over a specified time period.\n\n## **Virus epidemiological fitness:**\n\nQuantification of epidemiologic fitness is based largely on observational data and examines changes in distribution, prevalence, and composition of viral genotypes over time to infer their relative fitness.\n\n## **CUB(codon usage biases):**\n\nSynonymous codons are codons that encode for the same amino acid. Despite that, synonymous codons are generally used at different frequencies. This phenomenon can be seen in most genes and organisms, and it is called codon usage bias (CUB).\n\n## **Risk model:**\n\nA risk model is a statistical procedure for assigning to an individual a probability of developing a future adverse outcome in a given time period. The assignment is made by combining his or her values for a set of risk-determining covariates with incidence and mortality data and published estimates of the covariates’ effects on the outcome.[2]\n\n## **Ordinary differential equation:**\n\nDifferential equation dependent on only a single independent variable. Read More [3]\n\n## **Splines:**\n\nIn essence, splines are piecewise polynomials, joined at points called knots. The degree specifies the degree of the polynomials. A polynomial of degree 1 is just a line, so these would be linear splines. Cubic splines have polynomials of degree 3 and so on. The degrees of freedom (df) basically say how many parameters you have to estimate. They have a specific relationship with the number of knots and the degree, which depends on the type of spline.\n  >```Note : B splines are splines that have local control - when the control point/knot is moved there is no much differnce in the other part of the curve.```\n\n- For B-splines: $df=𝑘+degree$ if you specify the knots or $𝑘=df−degree$ if you specify the degrees of freedom and the degree.\n- For natural (restricted) cubic splines: $df=𝑘−1$ if you specify the knots or $𝑘=df+1$ if you specify the degrees of freedom.\n\n- As an example: A cubic spline (degree=3) with 4 (internal) knots will have $df=4+3=7$\ndegrees of freedom. Or: A cubic spline (degree=3) with 5 degrees of freedom will have $𝑘=5−3=2$ knots.\n\n- The higher the degrees of freedom, the \"wigglier\" the spline gets because the number of knots is increased.\n\n- The Boundary knots are the outermost two knots, ususally (but not always) placed at the minimum and maximum of 𝑥.\n- The other knots are called internal knots and when I talked about the number of knots I was always referring to the internal knots.[4]\n- [Introduction to Spline interpolation](https://www.youtube.com/watch?v=5tNApkOJX2M)\n- [Linear spline interpolation](https://www.youtube.com/watch?v=4Q1AQrUKgPk)\n- [cubic spline interpolation](https://www.youtube.com/watch?v=pBtqaK0PzrA)\n- [B-splines](https://www.youtube.com/watch?v=JwN43QAlF50)\n- [What is interpolation](https://www.youtube.com/watch?v=gT90n_J1hj8)\n\n## **Cubic Spline:**\n\n- [Cubic spline interpolation Reference Video](https://www.youtube.com/watch?v=pBtqaK0PzrA&t=0s)\n\n## **Convolution of functions:**\n\n- A convolution is an integral that expresses the amount of overlap of one function g as it is shifted over another function  f. It therefore \"blends\" one function with another.\n- Consider function **g** as impulse that acts on a continuous function **f** thereby modifying it a little. The impulse is not continuous or discreete because the impact of preceding impulse overlaps with the succeeding impulse. To account this we use convolution. Following is the convolution intergral.\n  $$$\n  (f*g)(t) = \\int_{0}^\\infin f(\\tau)g(t-\\tau)d\\tau\n  $$$\n\n- [Best way to understand convolution](https://betterexplained.com/articles/intuitive-convolution/)\n- [Convolution explained](https://youtu.be/x3Fdd6V_Hok)\n\n## **Over Dispersion:**\n\nIn statistics, overdispersion is the presence of greater variability (statistical dispersion) in a data set than would be expected based on a given statistical model.\n\n## **Logit function:**\n\n- A logit model is a link function that helps us to map the probability that is in the domain [0,1] to realnumber domain $[-\\infin,\\infin]$.\n- Logit function takes the log odds to change this domain of probability. Hence this is also called the log odds function.\n- It is the link function that is used to estimate the coefficients of the model. The model with calculated coefficients are fit on the predictor variable distribution using this link function (y variable)  [6],[7],[8]\n- My understanding - In the place of a cost function which is used to estimate the parameters in the logistic regression model, a  logit function is being used to turn the probability of the event into logodds based on which the coefficients can be derieved. ![reference from wikipedia](assets/images/logitmodel_logisticregression.png)\n\n## **Multivariate normal random variables:**\n\nMy undersatnding - a vector of random variables which is following a random distribution.\nThe value of the random variables is not known and these random variables denote different property of on statistical unit - one person or one country,etc.\nHere for each LTLA(1 statistical unit) a vector with l-1 random variables that denotes parameter for each of the l-1 lineage forms the multivariate normal variables.\n\n## **Independent and identically distributed random variables**\n\nIn probability theory and statistics, a collection of random variables is independent and identically distributed if each random variable has the same probability distribution as the others and all are mutually independent\n\n## **The prior probability:**\n\nThe Prior probability is the probability assigned to an event before the arrival of some information that makes it necessary to revise the assigned probability. The revision of the prior is carried out using Bayes' rule. The new probability assigned to the event after the revision is called posterior probability or conditional probability P(X=x|Y). A prior probability is the regular/classical probability $\\frac{\\# of favorable outcomes}{Total \\# possible outcomes}$\n\n## **Covariance:**\n\nCovariance is used to measure/observe the trend in variability in two or more random variables. This might sound like correlation. Correlation and covariance differ only in the sense that correlation-coefficient is a normalized version of covariance and is bound to the interval [-1,1]. Correlation talks about the strength and direction of the relationship between random variables whereas covariance talks only about the direction of the relationship.[9]\n\n## **Beta Distribution:**\n\n- This is a continuous probability distribution that is used to obtain the prior probability of probability of an event.  Consider a biased coin, the probability of heads and probability of tails cannot be 1/2; This biased coin is flipped N times and k occurances of head and N-k occurances of tail is observed. If we make the  parametres like $\\alpha$ and $\\beta$ take up the value k and N-k respectively, we can find the distribution of the probability of having heads. The domain is $0\\leq x\\le 1$ beacuse x denotes the probability. PDF of the function looks like $f(x)=B\\times x^{\\alpha} (1-x)^{\\beta}$. Where B is a normalization term\n- This is denoted as $Beta(\\alpha+1,\\beta+1)$\n- The $\\alpha$ and $\\beta$ control the shape of the curve\n- ![shape of the distribution](assets/images/Beta_distribution.png)\n- This distribution is often used as priori for probabilities\n- Beta distribution is univariate eg - the figure shows the Beta distribution for the probability of heads.\n  \n  > The $\\alpha$ and $\\beta$ are not necessarily count of the event. They are just parameters that can be set based on the likeliness of the event or can be set randomly.\n\n[Reference Video 1](https://www.youtube.com/watch?v=v1uUgTcInQk) \n[Reference video 2](https://www.youtube.com/watch?v=aVCImOiJklM)\n\n## **Dirichlet-multinomial distribution:**\n\n- Generalisation of the beta distribution for a vector of probabilities of random variables is Dirichlet distribution that is Dirichlet is multivariate and here we would have multiple parameters.\n- Providing the parameter value for the dirichlet gives a distribution from which probabilities can be sampled for each random variable.\n- Dirichlet-multinomial distribution is a posterior probability distribution that uses Dirichlet distribution as prior and multinomial likelihood\n- we use dirichlet when we just have a vector of of k categories and we use dirichlet-multinomial when we have along with the vector, observed data for n variables that can take any of the k categories.\n- The parameter alpha in the case of Dirichlet-multinomial will be summed with an additional term which accounts for multinomial likelihood.\n- Important condition $0\\le\\theta_j\\le1$ and $\\sum_{j=1}^k\\theta_j=1$ since $\\theta$ denotes the probability\n- PDF for Dirichlet distribution:\n  $$$\n  \\theta\\sim Dir(\\alpha),\\space \\alpha_1,\\alpha_2....\\alpha_k>0\\\\\n  Dir(\\alpha)=\\prod_{j=1}^k\\theta_{j}^{\\alpha_j-1}\n  $$$\n- PDF for Dirichlet-multinomial distribution:\n  $$$\n  P(\\theta|x_{1:n})\\propto P(x_{1:n}|\\theta)P(\\theta)\\\\\n  where \\space P(x_{1:n}|\\theta)\\space is\\space multinomial\\space likelihood\\\\ and\\space P(\\theta)\\space is\\space Dirichlet\\space prior\\\\\n  P(\\theta|x_{1:n})\\propto \\prod_{i=1}^n\\prod_{j=1}^k\\theta_{j}^{I(x_{ij}=1)}\\space \\prod_{j=1}^k\\theta_{j}^{\\alpha_j-1}\\space\\\\\n  $$$\n  > $N_j=\\sum_{i=1}^nI(x_{ij}=1)$ is the total number of times the random variables takes up category j in n trials. In a [[Multinomial Distribution|Growth_Rate_Estimation.Glossary#multinomial-distribution]] random variable can take up only one category in each trial\n  $$$\n  \\propto\\prod_{j=1}^k\\theta_j^{N_j}\\prod_{j=1}^k\\theta_{j}^{\\alpha_j-1}\\\\\n  \\propto\\prod_{j=1}^k\\theta_{j}^{N_j+\\alpha_j-1}\n  $$$\n- Normalising terms are not considerend in the above equations.[10]\n- [Refernce for dirichlet](https://www.youtube.com/watch?v=gWgsKyEjclw)\n  \n## **Multinomial Distribution:**\n\n- In probability theory, the multinomial distribution is a generalization of the binomial distribution. For example, it models the probability of counts for each side of a k-sided dice rolled n times. For n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories.\n- When K = 2 and n=1 it is Bernoulli distribution. When k=2 and n>1 it is Binomial distribution. When k>2 and n=1 it is categorical. When k>2 and n>1 it is multinomial\n- The multinomial distribution models the outcome of n experiments, where the outcome of each trial has a categorical distribution, such as rolling a k-sided die n times.\n\n## **Hierarchical Bayesian model:**\n\n- Bayesian hierarchical modelling is a statistical model written in multiple levels (hierarchical form) that estimates the parameters of the posterior distribution using the Bayesian method.The sub-models combine to form the hierarchical model, and Bayes' theorem is used to integrate them with the observed data and account for all the uncertainty that is present. The result of this integration is the posterior distribution, also known as the updated probability estimate, as additional evidence on the prior distribution is acquired.\n\n## **Negative Binomial Distribution:**\n\n The negative binomial distribution is the probability distribution of the number of successes before the rth failure in a Bernoulli process, with probability p of successes on each trial.\n\n## **Poisson Distribution:**\n\n- A Poisson distribution is a discrete probability distribution, meaning that it gives the probability of a discrete (i.e., countable) outcome.\n\n- The  Poisson distribution is used to predict or explain the number of events occurring within a given interval of time or space. “Events” could be anything from disease cases to customer purchases to meteor strikes. The interval can be any specific amount of time or space, such as 10 days or 5 square inches.\n\n- The Poisson distribution can be used if:\n\n1. Individual events happen at random and independently. That is, the probability of one event doesn’t affect the probability of another event.\n2. The mean number of events occurring within a given interval of time or space is known.\n3. This number is called λ (lambda), and it is assumed to be constant.\nWhen events follow a Poisson distribution, λ is the only thing you need, to know to calculate the probability of an event occurring a certain number of times. [11]\n\n> Poisson distribution: If $\\lambda =mean$ then the pdf of Poisson distribution is $P(X=k|\\lambda)=\\frac{\\lambda^ke^{-\\lambda}}{k!}$\n\n[What is poisson distribution and derivation of the formula part1](https://youtu.be/3z-M6sbGIZ0)<br>\n[What is poisson distribution and derivation of the formula part2](https://youtu.be/Jkr4FSrNEVY)\n\n> My understanding the Poisson distribution is similar to the binomial distribution in counting the number of success and failures but if we consider the trial in binomial distribution as time interval or space interval, then it is the poisson distribution. The difference is that in binomial distibution in a trial you get only one outcome but when considered as time interval then we can expect multiple outcomes - multiple success or failures. To bring the it to one outcome per unit time, the interval is granulated that is hours ----> minutes-----> seconds so the time interval n willl tend to infinity when we granulate it more and more. So basically poisson is a binomial distribution with n tending to infinity.\n\n## **Probability vs Likelihood:**\n\nProbability is used to find the chance of occurace of a particular situation whereas Likelihood is used to maximise the chances of occurance of a particular situation.\nProbability: $P(X=17|\\mu=15,\\sigma=2)$ So the chances of getting X=17 when the distribution has the given characteristics. The values that X would take can change but the the characteristic of the distribution will remmain. <br>\nLikelihood: $Likelihood(\\mu=15,\\sigma=2|X=17)$. Here the data distribution or the dataset features will be changed to get the maximum likelihood of getting X=17. [12] The likelihood can be said as the probability of getting X=17 when $\\mu=15,\\sigma=2$ so $L(\\mu=15,\\sigma=2|X=17)=P(X=17|\\mu=15,\\sigma=2)$ but it is not same as P(\\mu=15,\\sigma=2|X=17)\n\n## **Gamma Distribution:**\n\nGamma distribution is a continuous probability distribution used to model the time that is elapsed before $\\alpha$ occurances of an random event. Example calls to the pizza place - after how much time did the pizza place receive 10 calls. Or after how long there are 10000 defects in a production line. The Events are poisson process because the events occur independently and randomly.\n\nDerivation of the Gamma function:\n\n- Let X be elapsed time before $\\alpha$<sup>th</sup> occurance of the event. Let $\\theta$ be the average time between the occurances. Then the CDF of X is\n$$$\\\\\nP(X\\le x)=1- P(less\\space than\\space \\alpha\\space occurances\\space in\\space less\\space than\\space x\\space time)\n$$$\n- The subtrahend is a poisson distribution because it counts the number of occurances in a time unit. \n- The average number of times the event can occur in x time is $\\frac{x}{\\theta}$. So thats the mean for the poisson distribution. The expression inside the summation is the probability of exactly k occurances in time x.\n$$$\\\\\nP(X\\le x)=1-\\sum_{k=0}^{\\alpha-1}\\frac{(x/\\lambda)^ke^{-x/\\lambda}}{k!}, \\space x\\ge0\n$$$\nDifferentiating and simplifying this would give us the PDF of gamma distribution\n$$$\\\\\nf(x)=\\frac{x^{\\alpha-1}e^{-x/\\theta}}{\\Gamma(\\alpha)\\theta^\\alpha}, \\space x\\ge0\n$$$\nThe expected value for waiting time for $\\alpha$ occurances is given by $\\mu=\\alpha\\theta$ => $\\theta$ is the average time between each occurances, $\\alpha$ is the number of occurances so the average waiting time would be the product of both.\n\nThe variance of gamma distribution is $\\sigma^2=\\alpha\\theta^2\\\\$\n[Reference video](https://www.youtube.com/watch?v=cpW40zPdAQ8)\n\n## **Bayessian inference:**\n\n- My understanding - Bayessian theorem is used to claculate the posterior probability of a random variable given some observation. To find say P(A|B) we use P(B|A) along with prior probaility of P(A) and P(B). So calculating P(B|A) would be more easy than the otherway around thats why we use the bayesian inference to calculate P(A|B) with the easily calculated P(B|A).\n- [Bayes theorem derivation and explanantion](https://youtu.be/XQoLVl31ZfQ)\n- [Reference with multiple randome variables](https://math.stackexchange.com/questions/549887/bayes-theorem-with-multiple-random-variables)\n\n## **Coefficient of variation:**\nIn probability theory and statistics, the coefficient of variation (COV), also known as Normalized Root-Mean-Square Deviation (NRMSD), Percent RMS, and relative standard deviation (RSD), is a **standardized measure of dispersion of a probability distribution or frequency distribution**. It is defined as the ratio of the standard deviation $\\sigma$  to the mean $\\mu$  (or its absolute value,$|\\mu|$), and often expressed as a percentage (\"%RSD\"). The CV or RSD is widely used in analytical chemistry to express the precision and repeatability of an assay. \n$\\\\CV=\\frac{\\sigma}{\\mu}$\n\n## **Truncated Normal Distribution:**\n\nIn probability and statistics, the truncated normal distribution is the probability distribution derived from that of a normally distributed random variable by bounding the random variable from either below or above.\n\n## **Censoring (Right/Left/Interval):**\n\n+ In statistics, censoring is a condition in which the value of a measurement or observation is only partially known.\n+ Left censoring – a data point is below a certain value but it is unknown by how much.\n+ Interval censoring – a data point is somewhere on an interval between two values\n+ Right censoring – a data point is above a certain value but it is unknown by how much.\n\n## **Moment Generating function:**\nIn Statistics moments denote the characteristics of the distribution - the first order moment is the mean of the distribution, second order moment is the variance, third and fourth order moments are the skewness and kurtosis of the distribution respectively.\nA moment generating function is used to derieve the moment of the distribution. The probability distribution can be determined by its moment generating function.\nA Moment generating function of a random variable X is a function $M_X(s)$ and is defined as $M_X(s)=E[e^{sX}]$. Not all Random variables have moment generating function.If Expected value for X $E[exp(tX)]$ exists and is finite for all real numbers t belonging to a close interval $[-h,h]\\subseteq R$ with $h\\ge0$, then we say X possesses a moment generating function $M_X(t)=E[exp(tX)]$\n\n## **R-squared:**\nR-squared is a statistical measure that indicates how much of the variation of a dependent variable is explained by an independent variable in a regression model. Whereas correlation explains the strength of the relationship between an independent and a dependent variable, R-squared explains the extent to which the variance of one variable explains the variance of the second variable. $R^2$ is easy to intepret and easy to calculate too.\n\n## **Exponential Function and e (Euler's number):**\n\n- The Euler's number is used in an exponentially growing function. \n- e is used to describe the 100% continual growth for a end of a period. Consider the Growth for 1 time interval follows a trend $(1+r)$ where r is the rate and the number 1 is the already existing amount(100%). If this calculation is done for a subdivided time intervals (.5+.5) the this would become as $(1+\\frac{r}{2})^2$, this would result in a irrational number greater than 2 and less than 3. This generslised with the Euler's number . - If  To find the growth for x=2 periods then we use $e^x$.\n- 100 changes of 1 percent rate also gives e:- $(1+.01)^{100}=2.7048$ So we can say $growth=(e^{rate})^{time}$\n- $(1+.01)^{100}=e\\\\(1+.01)^{50}=(1+.01)^{\\frac{100}{2}}=e^{\\frac{1}{2}}$\n- e can match a stair case growth can be modelled with e into a smoother curve.[14]\n- [Refernce video regarding the e](https://youtu.be/pg827uDPFqA?feature=shared)\n  \n## **Latent period:**\nThe period from the time of infection to the time of becoming infectious is called the pre-infectious period or the latent period.\n![latent period](assets/images/Concept_of_incubation_period.webp)\n\n## **Contact Rate:**\nThe average number of contacts adequate for disease transmission by an individual per unit time. It can vary by time and it is not a constant qunatity.\n\n## **Expectation maximization algorithm:**\nThis algorithm is used to find the maximum likelihood parameters of a statistical model. These model apart from the unknown parameters also include known data observations. It is an itreative method EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step.\n\n## **Confidence interval:**\nThe confidence level is the overall capture rate if the method is used many times. The sample mean will vary from sample to sample, but the method estimate ± margin of error is used to get an interval based on each sample. CI% of these intervals capture the unknown population mean 𝜇. In other words, the actual mean will be located within the interval CI% of the time.\n\nConfidence, in statistics, is another way to describe probability. For example, if you construct a confidence interval with a 95% confidence level, you are confident that 95 out of 100 times the estimate will fall between the upper and lower values specified by the confidence interval.\n\nYour desired confidence level is usually one minus the alpha (α) value you used in your statistical test:\n\nConfidence level = 1 − a\n\nSo if you use an alpha value of p < 0.05 for statistical significance, then your confidence level would be 1 − 0.05 = 0.95, or 95%.\n\n## Log transform\nA log transform is did when the data distribution is very skewed. Transforming suck data by log would make the distribution clode to normal. [Log transformation](https://youtu.be/LCDiQxB5S84)\n\n## **Attack Rate:**\nThe percentage of the population eventually infected. If the total population is 15743 and 7463 people were finally infected then the AR is $\\frac{7463}{15743}*100=47%$. This can be calculated only when the epidemic is over and this can be calculated only in a closed population.\n\n## Eurler lotka equation:\n1. The Lotka-Euler equation is a mathematical expression used to study pop- ulation dynamics and growth, particularly in the context of demography and ecology. \n2. This equation is predominantly employed in the study of stable age populations, where age-specific birth and death rates remain constant over time.\n\n## CRAN Task view:\nCRAN task views aim to provide guidance which packages on the Comprehensive R Archive Network (CRAN) are relevant for tasks related to a certain topic. They give a brief overview of the included packages which can also be automatically installed using the ctv package. The views are intended to have a sharp focus so that it is sufficiently clear which packages should be included (or excluded) - and they are not meant to endorse the \"best\" packages for a given task [15].\n\n## Case Fatality ratio:\nThe fraction of cases that die after contracting a disease. The relative case fatality ratio is the factor by which the case fatality ratio in one group is greater or less than other group in a second group.\n\n## R class system:\n\n- R has 3 class systems while other program has only one.\n- s3 is \n[1]: <https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module3-Frequency-Association/PH717-Module3-Frequency-Association4.html#:~:text=Cumulative%20Incidence%20Versus%20Incidence%20Rate,-There%20are%20two&text=Cumulative%20incidence%20is%20the%20proportion,%22%20(person%2Dtime)>\n\n[2]: <Whittemore AS. Evaluating health risk models. Stat Med. 2010 Oct 15;29(23):2438-52. doi: 10.1002/sim.3991. PMID: 20623821; PMCID: PMC2990501>\n\n[3]: <https://www.mathsisfun.com/calculus/differential-equations.html>\n\n[4]: <https://stats.stackexchange.com/questions/517375/splines-relationship-of-knots-degree-and-degrees-of-freedom>\n\n[5]: <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9347870/>\n\n[6]: <https://www.geo.fu-berlin.de/en/v/soga-r/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html>\n\n[7]: <https://en.wikipedia.org/wiki/Logit>\n[8]: <https://datascience.stackexchange.com/questions/53226/what-is-the-purpose-of-logit-function-at-what-stage-of-model-building-process-t>\n[9]: <https://towardsdatascience.com/understanding-the-covariance-matrix-92076554ea44>\n[10]: <https://gregorygundersen.com/blog/2020/12/24/dirichlet-multinomial/>\n[11]: <https://www.scribbr.com/statistics/poisson-distribution/>\n[12]: <https://medium.com/swlh/probability-vs-likelihood-cdac534bf523>\n[13]: <https://s4be.cochrane.org/blog/2020/11/06/prevalence-vs-incidence-what-is-the-difference/#:~:text=Two%20types%20of%20incidence%20are,%27%20and%20%27incidence%20rate%27.>\n[14]:<https://betterexplained.com/articles/an-intuitive-guide-to-exponential-functions-e/#:~:text=e%20is%20the%20base%20rate,growing%20just%20a%20little%20bit.>\n[15]:<https://github.com/cran-task-views/ctv/>","n":0.015}}},{"i":21,"$":{"0":{"v":"GerstungLab","n":1},"1":{"v":"\n## Overall crux of the paper\n\nIn the gerstung lab paper the dynamics of lineages of SARS-CoV-2 that were studied across all LTLA using [[Hierarchical Bayesian model|Growth_Rate_Estimation.Glossary#hierarchical-bayesian-model]]. The whole idea is to fit the model to the incidence data in hand and estimate the relative historical prevalence that is while fitting a prior probability is used with more and more data comming in in each step the the posterior can be derived and uaed to increase the fit of the model.<br>\nFitting a Multivariate logistic regresssion model accounts for for the differences in the epidemiological dynamics between LTLAs. The relative growth rate of a lineage is condsiered identical across all the LTLA and they only differ by their proportion which is due to the difference in the rate of introduction of each lineage into a LTLA.\n>> The model calculates : Total and lineage specific local incidences, time dependent growth rate and aapproximate reproduction numbers.\n\nThe growth rate advantage of a lineage is reasoned out with the mutation in the lineage. Incidence, Growth rate and reproductoin number were all calculates by fitting various statistical model with the observed data.\n\nThe growth rates of new rare variant are stochastic due to random introduction and superspreading events. The growthrates are also influenced by the immunity of the population, the immunity of the populaation is not currently modelled now. \n\n## **Doubts and answers**\n\n1. 384 sample pools belonged to 324 Pangolineages - Does it mean each sample pool was a different lineage?\n   > Ans: 324 can include sublineages\n\n2. What does the vector b indicate? It is said as some lineage specific parameter.\n3. **HOW?** Relative proportions of lineages or lineage [[Prevalence |Growth_Rate_Estimation.Glossary#incidence-vs-prevalence]] :\n$$$\np(t)=\\cfrac{x(t)}{\\sum x(t)} \\propto e^{const+\\vec{b}t}\\\\\n$$$\nAns: I think this means the prevalence of a particular lineage is directly proportional to the e raised to the lineage specific parameter vector **$\\vec{b}$**.\n4. What does the h weekly and k-h monthly splines mean? I assume it is the number of knots in the spine.\n5. What does the equation  $\\delta(t)=\\delta(t-1\\times 7)\\space \\forall i \\in N$ mean? ($\\delta(t)$ is used as factor to account periodic difference in weekly testing pattern). Why is t from 1-6?\n\n> Ans: Don't bother because it is corrections that are brough about to get proper fit\n\n1. In Genomic prevalance what is the offset paramenters **C**?\n2. ![Didnt understand](assets/images/regarding_inverselogittransformation.png)Why l-1 dimension?\n3. I don't understand the intuition behind selecting $\\alpha_0\\space ,\\space \\alpha_1$ ![scrrenshot from the paper](assets/images/Dirichlet_multinomial_parameters.png) Having $\\alpha_0=0.01$ will bring effect only at the hundredth's decimal place of the parameter.\n4. I don't quite get the concept of ![Lineage specific reproduction number](assets/images/lineage_specific_reproduction_number.png)\n\n### **Important doubt:**\n\n- Why is the derivative of original basis used for claculating the growth rate and not the convoluted function? \n![from_the_paper](assets/images/Weekly_montlysplines_Gerstunglab.png)\n  If the function is not convoluted it intuitively means that infections occured during a former time is being reported at a later time. Finding the derivative of this and fitting the growth rate cannot be correct ,right?\n\n> - But in the Growth rates and R<sub>t</sub> section they claim r(t) as delay adjusted by equating it to derivative of f(t). ![delayadjusted](assets/images/delay_adjusted_Growth_rate.png)\n> - when $\\mu(t)$ is expected number of positive test cases daily and $f(t)$ is a function to capture \\# new infections at time t and $\\lambda(t)$ is the daily incidence per capita at time t :- $\\lambda(t) = log\\mu(t) - log(s)$. How will using the convoluted $f^*(t)$ to fit the percapita incidence in each LTLA be right? $f(t)$ doesn't account for the LTLA population.\n\n> Ans: These are the reasons for not reimplementing the paper.\n\n### **Confusion:**\n\n- proper definition of incidence?\n  \n> Ans: Incidence should take both time and population into consideration\n\n- It was said that: $\\lambda(t)=\\log(\\mu)-\\log(s)$ ; But the $\\log(s)$ is not considered anywhere thereafter\n    1. In the subsection Growth rate and R<sub>t</sub>  it is stated as $\\log(\\mu)=\\lambda$\n  Why is log(s) not considered.\n\n\n## Pillar 2 SARS-CoV-2 data\n\nPubilcly available SARS-CoV-2 test result data ![pillar2_example](assets/images/Pillar2_data_example.png) It is the number of positive PCR test cases grouped by specimen date.\n315 LTLA were considered and its population data was downloaded from the office of national statistics.\n\n## Data Handling\n\n```mermaid\ngraph \nA[281,178 randomly selected samples] --> |Random selection of samples but some metadata was used| B[Amplicon sequencing] -->|384 samples pools were sequenced| C[Pangolin Lineage assignment] --> D[Lineage prevelance computed from 281,178 genome sequences] --> E[Mapping genome to 315 LTLA] --> F[agrregating lineage by counts per week in each LTLA for 43 weeks] --> G[ 328 Pango lineages into 71 by phylogenetic tree] -->|Each resulting lineage contains 100 genomes| H[END]\n```\n\nsample pool : pool/batch  were samples are grouped together and the sent for sequencing. The samples are barcoded to be identified later. This is done to make the process fast,cost effective and simplified analysis.[Reference](https://www.illumina.com/techniques/sequencing/ngs-library-prep/multiplexing.html#:~:text=Sample%20multiplexing%2C%20also%20known%20as,or%20working%20with%20smaller%20genomes.)\n\n## About the model\n\n### Spatiotemporal genomic surveillance model\n\n- [[Hierarchical Bayesian model|Growth_Rate_Estimation.Glossary#hierarchical-bayesian-model]] - fits incidence data in a day and estimate the relative historical prevelance and transmission parameter. That is deriving posterior values for all the prior parameters using the present data.\n- Following is my derivation of the solution of [[Ordinary differential equation|Growth_Rate_Estimation.Glossary#ordinary-differential-equation]] that takes the form - The rate of change of  viral population: _\n$$$\nx'(t)=(\\vec{b}+r_0(t))*x(t) \\equiv \\frac{dx}{dt}=(\\vec{b}+r_0(t))*x(t)\\\\\n\\int \\frac{dx}{x(t)}=\\int (\\vec{b}+r_0(t))dt\\\\\nln(x(t)) + const = \\vec{b}t+const+\\int r_0(t)dt\\\\\nx(t)=e^{(\\vec{b}t+const+\\int r_0(t)dt)}\\\\\nx(t)=e^{(\\vec{b}t+const)}v(t) ; v(t) = e^{\\int(r_0(t)dt)}\\\\\n$$$\nRelative proportions of lineages or lineage [[Prevalence |Growth_Rate_Estimation.Glossary#incidence-vs-prevalence]] :\n$$$\np(t)=\\cfrac{x(t)}{\\sum x(t)} \\propto e^{const+\\vec{b}t}\\\\\n$$$\nTotal / [[Cumulative Incidence:|Growth_Rate_Estimation.Glossary#cumulative-incidence]] factorizes into : \n$$$\n\\mu (t)=v(t) \\sum e^{c+\\vec{b}t}\n$$$\n- **t** :- Time in days\n\n- **v(t)**  :- contributes a same factor to each of the lineage since r<sub>0</sub> is lineage independent. \n\n- **p(t)** :- Lineage [[ Prevalence|Growth_Rate_Estimation.Glossary#incidence-vs-prevalence]], Propotion of each of the lineage. It follows a multinomial logistic linear trajectory - because it is for different lineages. The ratio is directly propotional to $e^{c+\\vec{b}t}$\n\n- **r<sub>0</sub>(t)** : scalar time dependent logistic [[Growth rate|Growth_Rate_Estimation.Glossary#epidemic-growth-rate]]. This r<sub>0</sub> reflects lineage  independent transmission determinants - I assume this is calculated using overall secondary cases (for each lineages) and specified time interval and not intergeneration time. The lineages will differ only by the transmission intensity which I assume as the [[Reproduction Number|Growth_Rate_Estimation.Glossary#reproduction-number]] at specified time intervals and not intergeneration time \n\n- **$\\mu(t)$** :- Total incidence (incidence of all the lineages together at specified time interval)\n\n## Incidence\n\n- [[Incidence |Growth_Rate_Estimation.Glossary#incidence-vs-prevalence]] is the number of new cases at specified time for a specific population at the same time.\n- Let $\\mu(t)$ be the expected daily number of positive pillar 2 test\n- **s** is the population size in each LTLA(Lower Tier Local Authority)\n- $\\lambda(t)=log\\mu (t)-log(s)$ :- logarithimic daily incidence per capita at time t.\n- suppose function $f(t)$ captures the number of new infections at time t. But these new infections are only tested and reported after a delay - **u** that has  distribution **g**.\n- The possible overlap is that the infection occured in the previous time bin can be reported in the later time bin, so a convolution is required.\n- To include the delay that has a distribution **g**, the function f(t) and the delay are [[Convoluted |Growth_Rate_Estimation.Glossary#convolution-of-functions]].\n  $$$\n  f*(t) = \\int_{0}^\\infin g(u)f(t-u)du = (g*f)(t)\n  $$$\n\n- time from infection to test equals to the incubation time plus symptoms to test time. The distribution of later is not well defined. But in England the test should be taken within **5days** of the symptoms onset.\n- The incubation time that has been utilised has been modified to account the symptom to test time.\n  ![From the paper](assets/images/Delay_in_case_reporting_Gerstunglab.png)\n\n- To parametrize (to know / fix on the parameters) the changes in logrithmic incidence, h weekly and k-h monthly cubic base [[splines|Growth_Rate_Estimation.Glossary#splines]] $f(t)=(f_1(t),...f_k(t))$are fit to the data. I assume k and h are number of knots in the spline function. The spline is convoluted with the function **g** that denotes the time delay thereby making the spline $f^*(t)=f_{1}^*(t)...f_{k}^*(t)$.\n- The convoluted spline is used to fit the $\\lambda(t)$ - logarithmic per capita incidence\n  $$$\n  \\lambda(t)=B\\times f^*(t)\\space ; B \\in R^{m\\times k} \n$$$\n- B :- matrix of coeffictients that is used for fitting the $\\lambda(t)$\n- m :- for each LTLA\n- k :- each spline function.\n- The coefficients have a normal [[prior probability|Growth_Rate_Estimation.Glossary#the-prior-probability]] distribution with zero as mean and $\\sigma_j=0.2$ as sd for weekly splines and $\\sigma_j=1$ for monthly splines. The choice regularize the amplitude of the splines with some instabilities at the end of the time series. Having $\\sigma_j=1$  for monthly spline coefficients makes the monthly splines less regularized (high sd means the data - coefficients has high variance.When these coefficients are used then there is less regularization). This less regularization is not a problem because the monthly splines reflects the trend on the scale of several weeks so less noise.\n- The original spline function's derivative $f'(t)$ (Rate of change of number of new infections at time t) is used to calculate the growthrate\n- [[Important doubt|meet.2023.08.09#important-doubt]]\n- $\\delta(t)$ - factor accounting for the periodic difference in the testing pattern like $30 \\%$ lower specimen taken during the weekends. \n- I think $\\mu$ is obtained from the $\\lambda(t)$ which was obtained from the convoluted fuction $f^*(t)$ and the $\\delta(t)$ factor is multiplied with $\\mu(t)$. Probably this gives the correct number of cases per day.\n- $\\tilde{\\mu} = \\mu(t) . \\delta(t)$\n- The total incidence $\\tilde{\\mu}$ was fit to the observed number of positive tests X by a negative binomial with a dispersion(spread of the distribution - SD or variance or interquartile range) $\\omega=10$. The dispersion is an [[Over Dispersion|Growth_Rate_Estimation.Glossary#over-dispersion]] which would buffer the uncorrelated fluctuations.\n- $X(t) \\sim  NB(\\tilde{\\mu}(t),\\omega)$\n\n## **Growth Rates:**\n\n- Answer for the [[Confusion|meet.2023.08.09#confusion]]:\n- [[Epidemic Growth rate|Growth_Rate_Estimation.Glossary#epidemic-growth-rate]] can also be defined as rate of change of log-transformed incidence which is $\\lambda$ hence $r(t)=\\lambda'(t)$\n- which is $r(t)=B\\times f'(t)$.\n\n## **Reproductive number  R<sub>t</sub>:**\n\n- For reasons of simplicity laplace transform of the [[Generation Time|Growth_Rate_Estimation.Glossary#generation-time]] is not adopted instead,\n- R<sub>t</sub> values are approximated by multiplying the logarithimic growth rates with a value of $\\overline{\\tau}_e=5.1d$. This value was found to be reasonable approximation for the convolution.\n- $\\log(\\rho(t)) \\approx \\frac{d \\log(\\mu(t))}{dt}*\\overline{\\tau}_e = r(t)\\overline{\\tau}_e$\n\n## **Genomic Prevalance:**\n\n- A Logistic linear model for each LTLA is being used to model the dynamics of each lineage prevelance in each LTLA. \n- The logistic prevalance is defined as L(T)= logit(P(t)) (more on [[Logit function|Growth_Rate_Estimation.Glossary#logit-function]]. Prevalance is also called as [[The prior probability|Growth_Rate_Estimation.Glossary#the-prior-probability]] [1]). The prevalence is in [0,1], the logit function changes it to real  number domain. \n- The Logistic prevalence  L(t) is modelled using piecewise linear expression : $L(t)=C+b*t_+$ (b- lineage specific growth advantage, C matrix with offset term with dimention $(LTLA\\times Lineages)$) which I assume is similar to the features and coefficients combo defining of the independent variables, like the righthand side of the following equation\n- $\\pi=\\beta_0+\\beta_1x_1+\\beta_2x_2+....+\\beta_kx_k$\n- $t_+ = t-t_0\\space (if\\space t>t_0)\\space else -\\infin\\space$ where t<sub>0</sub> is the introduction time.\n- This time term is introduced to suggest that the lineages can be absent before this time, since the exact time of lineage introduction is not known a 3 week period before the time of observation is chosen. together it is t<sub>0</sub>.\n- $t_0\\sim Unif(-14,0)+t^{obs}_0$. I assume that for each lineage the buffer time chosen varies thats why there is a uniform distribution.\n- Doubt regarding $L_{.,0}(t)=0$\n- The offset parameter **C** is a prameter set that is  modelled for each LTLA as an independently distributed [[Multivariate normal randomvariables|Growth_Rate_Estimation.Glossary#multivariate-normal-randomvariables]] with a lineage specific mean **c** and covariance matrix $\\Sigma=10\\times I_{(l-1)\\times (l-1)}$.\n\n> - I assume **C** would be like - say there are 35 LTLA and 6 lineages, Then there might be 35 vectors with l-1 = 5 elements :\n> - $LTLA_1=\\begin{bmatrix}l1\\\\l2\\\\l3\\\\l4\\\\l5\\\\\\end{bmatrix}....LTLA_{35}=\\begin{bmatrix}l1\\\\l2\\\\l3\\\\l4\\\\l5\\\\\\end{bmatrix}$\n> - Lineage specific mean $C_1=\\frac{LTLA_1(l_1)+LTLA_2(l_1)+....LTLA_{35}(l_1)}{35}$\n> - [[Covariance|Growth_Rate_Estimation.Glossary#covariance]] of the parameters among the lineages (I assume) for each LTLA is given by  $\\begin{bmatrix}var(l_1,l1)&covar(l_1,l_2)&covar(l_1,l_3)&covar(l_1,l_4)&covar(l_1,l_5)\\\\covar(l_2,l1)&var(l_2,l_2)&covar(l_2,l_3)&covar(l_2,l_4)&covar(l_2,l_5)\\\\covar(l_3,l1)&covar(l_3,l_2)&var(l_3,l_3)&covar(l_3,l_4)&covar(l_3,l_5)\\\\.&.&.&.&.\\\\var(l_5,l1)&covar(l_5,l_2)&covar(l_5,l_3)&covar(l_5,l_4)&var(l_5,l_5)\\end{bmatrix}=10\\times I_{l-1\\times l-1}$\n> So I assume for each LTLA there is a covariance matrix.\n- The lineage specific factor **b** and lineage specific mean off-set **c** are modelled using [[IID|Growth_Rate_Estimation.Glossary#independent-and-identically-distributed-random-variables]] Normal [[prior probability distribution|Growth_Rate_Estimation.Glossary#the-prior-probability]].\n-  $b\\sim N(0,0.2)$ and $c\\sim N(-10,5)$ which means b and c are said to follow a normal distribution with the stated mean and variance\n\n- **MY assumption** :\n    1. G(t) is the total number of genomes sequenced in a given LTLA.\n    2. I think Y(t) is the $\\theta$\n    3. p(t) which is the prevalance of each lineages. The prevalance is used as the paramenter of [[Dirichlet-multinomial distribution|Growth_Rate_Estimation.Glossary#dirichlet-multinomial-distribution]].\n    4. $Y_{i,.}(t)\\sim DirMult(\\alpha_0+\\alpha_1P_{i,j}(t),G_i(t))$. I think the i,. in $Y_{i,.}(t)$ and in $P_{i,j}(t)$ denotes (i)LTLA, (.)all lineages.\n    5. That is for each LTLA the probability distribution of all the lineages are found using this distribution.\n    6. Doubts regarding $\\alpha_0$ and $\\alpha_1$\n\n## **Lineage specific incidence and growth rate:**\n\n- Multiplying total incidence $\\mu$ in each of the LTLA with corresponding lineage prevalances for each lineage will give the lineage specific incidence. \n$M_{.,j}(t)=\\mu(t).P_{.,j}\\space for\\space j=0,.....l-1$\n- for lineage specific reproductive number R<sub>t</sub> (didn't understand)\n\n## **Phylographic analysis:**\n- To infer the introductory events of the VOCs in UK. sequences of VOCs along with the release dates were taken and the phylogeny was constructed to get the lineages and their sub lineages.\n- The introductory events of these VOCs into UK were considered if it is supported by any mirgratory history and transmission of such variant in UK.\n  \n## Limitations:\n- The transmission is modelled as determininstic process but it is a stochastic process.\n- Transmission between LTLA were not considered.\n- The inferred growth rates also cannot identify a particular mecha- nism of altered transmission. Biological mechanisms include a higher viral load, longer infectivity or greater susceptibility\n- Immunity changes has to be considered.\n- As the total incidence is modelled on the basis of the total number of positive PCR tests, it may be influenced by testing capacity\n\n\n## References\n\n[Vöhringer, H.S., Sanderson, T., Sinnott, M. et al. Genomic reconstruction of the SARS-CoV-2 epidemic in England. Nature 600, 506–511 (2021).](https://doi.org/10.1038/s41586-021-04069-y)\n[1]: <https://online.stat.psu.edu/stat509/lesson/17/17.3>","n":0.021}}}]}
